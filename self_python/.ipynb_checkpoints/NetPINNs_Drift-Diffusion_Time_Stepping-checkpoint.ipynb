{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINNs on Graphs\n",
    "\n",
    "This notebook accompanies the paper\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we describe and illustrate the methodology proposed in the aforementioned paper.\n",
    "Here, we deal with the solution of a drift-diffuion equation on a metric graph.\n",
    "A metric graph is an undirected graph that consists of a set of vertices $\\mathcal V$ and edges $\\mathcal E$ where in contrast to combinatorial graphs a length $l_e$ is assigned to each edge $e \\in \\mathcal E$.\n",
    "Each edge $e \\in \\mathcal E$ connects a pair of nodes $(v_{e_a},v_{e_b})$ with $v_{e_a}, v_{e_b} \\in \\mathcal V$\n",
    "\n",
    "We consider the drift-diffusion equation posed on each edge\n",
    "\n",
    "$$\n",
    "\\partial_t u = \\partial_x ( \\varepsilon \\partial_x \\rho_e - f(\\rho_e) \\partial_x V_e), \\quad e \\in \\mathcal E\n",
    "$$\n",
    "\n",
    "where $\\rho_e : [0,l_e] \\times (0,T) \\to \\mathbb{R}_+$ describes, on each edge, the concentration of some quantity while $V_e: [0,l_e] \\times(0,T)\\to \\mathbb{R}_+$ is a given potential and $\\varepsilon > 0$ a given constant, typically small.\n",
    "\n",
    "To make this a well-posed problem, we need a set of initial conditions as well as coupling conditions in the vertices.\n",
    "- For vertices $v \\in \\mathcal V_{\\mathcal K} \\subset \\mathcal V$, we apply homogeneous Neumann-Kirchhoff conditions, i.e., there holds\n",
    "$$\n",
    "\\sum_{e \\in \\mathcal{E}_v} J_e \\, n_{e} (v) = 0 \\quad v \\in \\mathcal V_{\\mathcal K},\n",
    "$$\n",
    "where we additionally ask the solution to be continuous over the edges, i.e.\n",
    "$$\n",
    "p_e(v) = p_{e^{'}}(v)\n",
    "\\quad \\text{for all } v \\in \\mathcal{V}_{\\mathcal K}, e, e^{'} \\in \\mathcal{E}_v\n",
    "$$\n",
    "with $\\mathcal E_v$ the edge set incident to the vertex $v$.\n",
    "- For vertices $v \\in \\mathcal V_{\\mathcal D} := \\mathcal V \\setminus \\mathcal{V}_{\\mathcal K}$ the solution fulfills flux boundary conditions\n",
    "$$\n",
    "J_e \\, n_e (v) = - \\alpha_v \\, (1-u_v) + \\beta_v \\, u_v \\quad \\text{for all } e \\in \\mathcal E_v.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as netx\n",
    "from time import time\n",
    "DTYPE='float64'\n",
    "timestepmode = 'implicit'\n",
    "tf.keras.backend.set_floatx(DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up class GraphPINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the class `GraphPINN`, which is employed in the subsequent code.\n",
    "The idea is to have one vanilla `PINN` for each edge which are connected via boundary and vertex conditions which are enforced weakly.\n",
    "\n",
    "---\n",
    "\n",
    "First, we define the model for a `PINN` which consists of one scaling layer, a number of fully connected hidden layers and one final output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class PINN(tf.keras.Model):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self, lb, ub,\n",
    "                 output_dim=1,\n",
    "                 num_hidden_layers=3,\n",
    "                 num_neurons_per_layer=20,\n",
    "                 activation='tanh',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.input_dim = lb.shape[0]\n",
    "        self.output_dim = output_dim\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "        # Define NN architecture\n",
    "        \n",
    "        # Scaling layer to map input to the interval [-1, 1]\n",
    "        #self.scale = tf.keras.layers.Lambda(\n",
    "        #    lambda x: 2.0 * (x - lb) / (ub - lb) - 1.0)\n",
    "        \n",
    "        # Inititialize num_hidden_layers many fully connected dense layers\n",
    "        self.hidden = [tf.keras.layers.Dense(num_neurons_per_layer,\n",
    "                                             activation=tf.keras.activations.get(\n",
    "                                                 activation),\n",
    "                                             kernel_initializer=kernel_initializer) for _ in range(self.num_hidden_layers)]\n",
    "        \n",
    "        # Output layer\n",
    "        #self.out = tf.keras.layers.Dense(output_dim, activation=None)\n",
    "        self.out = tf.keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "        \n",
    "    def call(self, X):\n",
    "        \"\"\"Forward-pass through neural network.\"\"\"\n",
    "        \n",
    "        #Z = self.scale(X)\n",
    "        Z = X\n",
    "        \n",
    "        for i in range(self.num_hidden_layers):\n",
    "            Z = self.hidden[i](Z)\n",
    "            \n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we rely on the package [NetworkX](https://networkx.org/).\n",
    "An alternative approach would be to employ [igraph](https://igraph.org/), which seems to be more lightweight.\n",
    "\n",
    "Next, we set up the class for a graph PINN which takes either an adjacency matrix $A$ or a `MultiDiGraph` as input `inp` to define the network as well as the Dirichlet data as a list of pairs $(i, u_i)_{i=1}^{n_D}$ corresponding to $u(v_i) = u_i$.\n",
    "*Notes*:\n",
    "- we define our graph as a `MultiDiGraph` since graphs imported from [OpenStreetMap](https://www.openstreetmap.de/) obey this format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a network which is determined by its\n",
    "adjacency matrix $A \\in \\mathbb{R}_+^{n_v \\times n_v}$ with $n_v$ the number of vertices.\n",
    "Note that this matrix is not symmetric, as it belongs to a *directed* graph.\n",
    "Here, an entry $a_{i,j} > 0$ indicates that there is an edge starting in vertex $i$ and ending in vertex $j$ with length $a_{i,j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = 5\n",
    "# Specify adjacency matrix\n",
    "if adj == 1:\n",
    "    A = np.array([[0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 1, 0, 1, 0, 0, 0],\n",
    "                 [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                 [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                 [0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                ], dtype=np.int16)\n",
    "    # Set boundaries\n",
    "    tmin = 0.\n",
    "    tmax = 1.\n",
    "    xmin = 0.\n",
    "    xmax = 0.1\n",
    "    \n",
    "    u0 = lambda x : 0\n",
    "    dirichletNodes = np.array([0, 7])\n",
    "    dirichletAlpha = np.zeros(8)\n",
    "    dirichletBeta = np.zeros(8)\n",
    "    dirichletAlpha[0] = .8\n",
    "    dirichletBeta[7] = .5\n",
    "                              \n",
    "    \n",
    "    eps = 0.01\n",
    "    def f(u):\n",
    "        return u * (1-u)\n",
    "    \n",
    "    def df(u):\n",
    "        return 1 - 2*u\n",
    "    \n",
    "    def pde(u, ut, ux, uxx):\n",
    "        return ut - eps * uxx + df(u) * ux\n",
    "    \n",
    "    def flux(u, ux):\n",
    "        return -eps * ux + f(u)\n",
    "\n",
    "    def initial_cond(x):\n",
    "        return np.zeros_like(x)\n",
    "    \n",
    "elif adj == 2:\n",
    "    \n",
    "    A = np.array([[0, 1],\n",
    "                 [0, 0]], dtype=np.int16)\n",
    "    pos = np.array([[0,0],[1,0]])\n",
    "    \n",
    "    # Set boundaries\n",
    "    tmin = 0.\n",
    "    tmax = 10.\n",
    "    xmin = 0.\n",
    "    xmax = 1.\n",
    "    \n",
    "    eps = .01\n",
    "\n",
    "    dirichletNodes = np.array([0, 1])\n",
    "    dirichletAlpha = np.array([0.7, 0.0])\n",
    "    dirichletBeta = np.array([0.0, 0.8])\n",
    "    \n",
    "    def f(u):\n",
    "        return u * (1-u)\n",
    "    \n",
    "    def df(u):\n",
    "        return 1 - 2*u\n",
    "    \n",
    "    def pde(u, ut, ux, uxx):\n",
    "        return ut - eps * uxx + df(u) * ux\n",
    "    \n",
    "    def flux(u, ux):\n",
    "        return -eps * ux + f(u)\n",
    "    \n",
    "    def initial_cond(x):\n",
    "        return tf.zeros_like(x)\n",
    "    \n",
    "elif adj == 5:\n",
    "    A = np.array([[0, 0, 1, 0, 0, 0],\n",
    "                  [0, 0, 1, 0, 0, 0],\n",
    "                  [0, 0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 1],\n",
    "                  [0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0]], dtype=np.int16)\n",
    "    \n",
    "    pos = np.array([[0.0, 0.0],\n",
    "                [0.0, 1.0],\n",
    "                [0.5, 0.5],\n",
    "                [0.5+np.sqrt(2)/2, 0.5],\n",
    "                [1.0+np.sqrt(2)/2, 0.0],\n",
    "                [1.0+np.sqrt(2)/2, 1.0]])\n",
    "    # Set boundaries\n",
    "    tmin = 0.\n",
    "    tmax = 10.\n",
    "    xmin = 0.\n",
    "    xmax = 1.\n",
    "    \n",
    "    dirichletNodes = np.array([0, 1, 4, 5])\n",
    "    # Changed this!\n",
    "    dirichletAlpha = np.array([0.9, 0.3, 0., 0., 0., 0.])\n",
    "    dirichletBeta = np.array([0.0, 0.0, 0., 0., 0.8, 0.1])\n",
    "                              \n",
    "    eps = 1e-2\n",
    "    def f(u):\n",
    "        return u * (1-u)\n",
    "    \n",
    "    def df(u):\n",
    "        return 1 - 2*u\n",
    "    \n",
    "    def pde(u, ut, ux, uxx):\n",
    "        return ut - eps * uxx + df(u) * ux\n",
    "    \n",
    "    def flux(u, ux):\n",
    "        return -eps * ux + f(u)\n",
    "    \n",
    "    def initial_cond(x):\n",
    "        return np.zeros_like(x)\n",
    "\n",
    "\n",
    "# Lower bounds\n",
    "lb = np.array([tmin, xmin], dtype=DTYPE)\n",
    "\n",
    "# Upper bounds\n",
    "ub = np.array([tmax, xmax], dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph():\n",
    "    \n",
    "    def __init__(self, inp, dirichletNodes, dirichletAlpha, dirichletBeta, lb, ub, pos=None):\n",
    "        \n",
    "        if isinstance(inp, netx.classes.multidigraph.MultiGraph):\n",
    "            self.G = inp\n",
    "            self.A = netx.adjacency_matrix(G).toarray()\n",
    "            \n",
    "        else:\n",
    "            # Store adjacency matrix\n",
    "            self.A = A\n",
    "            # Define networkx multigraph\n",
    "            self.G = netx.MultiDiGraph(A)\n",
    "        \n",
    "        self.dirichletNodes = dirichletNodes\n",
    "        self.dirichletAlpha = dirichletAlpha\n",
    "        self.dirichletBeta = dirichletBeta\n",
    "        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        \n",
    "        # Get number of vertices\n",
    "        self.n_v = self.A.shape[0]\n",
    "        \n",
    "        # Determine lists of edges and lengths\n",
    "        self._determineEdgeList()\n",
    "        \n",
    "        # Determine list of vertices and incoming as well as outgoing edges\n",
    "        self._determineVertexList()\n",
    "        \n",
    "        # Determine graph layout if necessary\n",
    "        if pos is None:\n",
    "            self.pos = netx.kamada_kawai_layout(self.G)\n",
    "        else:\n",
    "            if isinstance(pos, np.ndarray):\n",
    "                self.pos = self.pos_array_to_dict(pos)\n",
    "            else:\n",
    "                raise ValueError('Check pos argument.')\n",
    "        \n",
    "    def _determineEdgeList(self):\n",
    "        \"\"\"Determine edge matrix and weight vector.\n",
    "        This could also be accomplished by a loop over `G.edges`:\n",
    "            for e in G.edges:\n",
    "                print(e)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.E = []\n",
    "        self.W = []\n",
    "        \n",
    "        for i in range(self.n_v):\n",
    "            for j in range(i + 1, self.n_v):\n",
    "                aij = self.A[i, j]\n",
    "                if aij > 0:\n",
    "                    #print('Connectivity between i: {} and j: {}'.format(i,j))\n",
    "                    self.E.append([i, j])\n",
    "                    self.W.append(aij)\n",
    "\n",
    "        # Get number of edges\n",
    "        self.ne = len(self.E)\n",
    "        \n",
    "    def _determineVertexList(self):\n",
    "        \n",
    "        self.Vin = [[] for _ in range(self.n_v)]\n",
    "        self.Vout = [[] for _ in range(self.n_v)]\n",
    "        \n",
    "        self.inflowNodes = []\n",
    "        self.outflowNodes = []        \n",
    "        \n",
    "        for i, e in enumerate(self.E):\n",
    "            # Unpack edge\n",
    "            vin, vout = e\n",
    "            self.Vin[vout].append(i)\n",
    "            self.Vout[vin].append(i)\n",
    "            \n",
    "        for i in range(self.n_v):\n",
    "            if self.Vin[i] and (not self.Vout[i]):\n",
    "                self.outflowNodes.append(i)\n",
    "\n",
    "            if (not self.Vin[i]) and self.Vout[i]:\n",
    "                self.inflowNodes.append(i)\n",
    "        self.outflowNodes = np.array(self.outflowNodes)\n",
    "        self.inflowNodes = np.array(self.inflowNodes)\n",
    "        self.innerVertices = np.setdiff1d(np.arange(self.n_v), self.dirichletNodes)\n",
    "            \n",
    "    def plotGraph(self, **kwargs):\n",
    "\n",
    "        netx.draw(self.G, pos=self.pos, with_labels=True, **kwargs)\n",
    "    \n",
    "    def pos_array_to_dict(self, pos):\n",
    "        pos_dict = dict()\n",
    "        for i in range(pos.shape[0]):\n",
    "            pos_dict[i] = pos[i,:]\n",
    "        return pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69992c4df99b40faac6439e7fed8a89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vin: [[], [], [0, 1], [2], [3], [4]]\n",
      "Vout: [[0], [1], [2], [3, 4], [], []]\n",
      "inner vertices [2 3]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "graph = Graph(A, dirichletNodes, dirichletAlpha, dirichletBeta, lb, ub, pos)\n",
    "graph.plotGraph()\n",
    "print('Vin:', graph.Vin)\n",
    "print('Vout:', graph.Vout)\n",
    "print('inner vertices', graph.innerVertices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw collocation points uniformly or take them equidistantly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step size:  0.01\n"
     ]
    }
   ],
   "source": [
    "mode = 'deterministic'\n",
    "#mode = 'uniform'\n",
    "\n",
    "N_0 = 200\n",
    "N_b = 1000\n",
    "N_r = 100\n",
    "if timestepmode == 'implicit':\n",
    "    if mode == 'deterministic':\n",
    "        t_r = tf.linspace(lb[0], ub[0], N_b + 1)\n",
    "        #t_r = tf.cast(tf.linspace(lb[0], ub[0], N_b + 1), DTYPE)\n",
    "        #x_r = tf.cast(tf.linspace(lb[1], ub[1], N_0 + 1), DTYPE)\n",
    "        x_r = tf.linspace(lb[1], ub[1], N_0 + 1)\n",
    "        x_r = tf.reshape(x_r, (-1,1))\n",
    "    elif mode == 'uniform':\n",
    "        t_r = tf.linspace(lb[0], ub[0], N_b + 1)\n",
    "        x_r = tf.random.uniform((N_0, 1), lb[1], ub[1], dtype=DTYPE)    \n",
    "        x_r = tf.reshape(x_r, (-1,1))\n",
    "else: \n",
    "    if mode == 'deterministic':\n",
    "\n",
    "        # Uniform distributed collocation points\n",
    "        t_r = tf.linspace(lb[0], ub[0], N_b+1)\n",
    "        x_r = tf.linspace(lb[1], ub[1], N_0+1)\n",
    "        tt, xx = tf.meshgrid(t_r,x_r)\n",
    "        X_r = tf.concat([tf.reshape(tt,(-1,1)), tf.reshape(xx,(-1,1))], axis=1)\n",
    "\n",
    "    elif mode == 'uniform':\n",
    "\n",
    "        # Set random seed for reproducible results\n",
    "        tf.random.set_seed(0)\n",
    "\n",
    "        X_r = tf.random.uniform((N_r,2), lb, ub, dtype=DTYPE)\n",
    "\n",
    "        # Draw uniform sample points for initial boundary data\n",
    "        t_0 = tf.ones((N_0,1), dtype=DTYPE)*lb[0]\n",
    "        x_0 = tf.random.uniform((N_0,1), lb[1], ub[1], dtype=DTYPE)\n",
    "        X_0 = tf.concat([t_0, x_0], axis=1)\n",
    "\n",
    "        # Boundary data\n",
    "        t_b = tf.random.uniform((N_b,1), lb[0], ub[0], dtype=DTYPE)\n",
    "        x_l = tf.ones((N_b,1), dtype=DTYPE) * lb[1]\n",
    "        X_l = tf.concat([t_b, x_l], axis=1)\n",
    "\n",
    "        x_u = tf.ones((N_b,1), dtype=DTYPE) * ub[1]\n",
    "        X_u = tf.concat([t_b, x_u], axis=1)\n",
    "\n",
    "        X_b = tf.concat([X_l, X_u], axis=0)\n",
    "\n",
    "        # Draw uniformly sampled collocation points\n",
    "        t_r = tf.random.uniform((N_r,1), lb[0], ub[0], dtype=DTYPE)\n",
    "        x_r = tf.random.uniform((N_r,1), lb[1], ub[1], dtype=DTYPE)\n",
    "        X_r = tf.concat([t_r, x_r], axis=1)\n",
    "        X_data = tf.concat([X_0, X_b, X_r], axis=0)\n",
    "        \n",
    "    # Draw collocation points\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(X_r[:,0].numpy(), X_r[:,1].numpy(),color='red',alpha=0.3)\n",
    "    ax.scatter(X_0[:,0].numpy(), X_0[:,1].numpy(), color='blue', alpha=0.5)\n",
    "    ax.scatter(X_b[:,0].numpy(), X_b[:,1].numpy(), color='cyan', alpha=0.5)\n",
    "    ax.set_xlabel('t')\n",
    "    ax.set_ylabel('x')\n",
    "    \n",
    "print('Time step size: ', t_r[1].numpy() - t_r[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully implicit time stepping scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesteppingPINNSolver(object):\n",
    "    def __init__(self, graph, t_r, x_r):\n",
    "        \n",
    "        self.graph = graph\n",
    "        self.ne = self.graph.ne\n",
    "        \n",
    "        self._setupNNs()\n",
    "        \n",
    "        self.t = t_r\n",
    "        self.x = x_r\n",
    "        self.dt = t_r[1].numpy() - t_r[0].numpy()\n",
    "        \n",
    "        self.nx = x_r.shape[0]\n",
    "        self.nt = t_r.shape[0]\n",
    "\n",
    "        # Initialize history of losses and global iteration counter\n",
    "        self.hist = []\n",
    "        self.iter = 0\n",
    "        self.current_loss = 999.\n",
    "        \n",
    "        self.idx = 1\n",
    "        \n",
    "        self.U = []\n",
    "        self.uold = []\n",
    "        for i in range(self.ne):\n",
    "            self.uold.append(tf.Variable(initial_cond(self.x)[:, 0]))\n",
    "            self.U.append(1e5*np.ones(shape=(self.nt ,self.nx)))\n",
    "            self.U[i][0, :] = self.uold[i].numpy()\n",
    "            \n",
    "        # Call each network once to initialize trainable variables\n",
    "        self.trainable_variables = []\n",
    "        for i in range(self.ne):\n",
    "            self.NNs[i](tf.constant([[1.]], dtype=DTYPE))\n",
    "            self.trainable_variables.append(self.NNs[i].trainable_variables)\n",
    "            \n",
    "        # Setup auxiliary variables for vertex values to ensure continuity\n",
    "        self._setupVertexVariables()\n",
    "        \n",
    "        for i, v in enumerate(self.graph.innerVertices):\n",
    "            self.trainable_variables.append([self.vertexVals[i]])\n",
    "        \n",
    "        self.nvar = len(self.trainable_variables)\n",
    "        \n",
    "    def _setupNNs(self):\n",
    "        \n",
    "        self.NNs = []\n",
    "        for i, e in enumerate(self.graph.E):\n",
    "            self.NNs.append(PINN(lb=self.graph.lb, ub=self.graph.ub))\n",
    "    \n",
    "        print('Initialized {:d} neural nets.'.format(len(self.NNs)))\n",
    "            \n",
    "\n",
    "    def _setupVertexVariables(self):\n",
    "        \n",
    "        self.vertexVals = []\n",
    "        for _ in self.graph.innerVertices:\n",
    "            # self.vertexVals.append(tf.Variable(tf.random.uniform(shape=(self.nb,)), trainable=True, dtype=DTYPE))\n",
    "            self.vertexVals.append(tf.Variable(tf.random.uniform(shape=(1,), dtype=DTYPE), trainable=True))\n",
    "    \n",
    "    def _fvals0(self, x):\n",
    "\n",
    "        # Initialize lists for values and derivatives\n",
    "        u = []\n",
    "        for i in range(self.ne):\n",
    "            u.append(self.NNs[i](x)[:,0])\n",
    "\n",
    "        return u\n",
    "    \n",
    "    def _fvals1(self, x):\n",
    "        \n",
    "        # Initialize lists for values and derivatives\n",
    "        u = []\n",
    "        ux = []\n",
    "        \n",
    "        for i in range(self.ne):\n",
    "            \n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                # Watch variables representing t and x during this GradientTape\n",
    "                tape.watch(x)\n",
    "\n",
    "                # Compute current values u(t,x)\n",
    "                u.append(self.NNs[i](x)[:, 0])\n",
    "            ux.append(tape.gradient(u[i], x)[:, 0])\n",
    "            \n",
    "            del tape\n",
    "                \n",
    "        return u, ux\n",
    "    \n",
    "    def _fvals2(self, x):\n",
    "        \n",
    "        # Initialize lists for values and derivatives\n",
    "        u = []\n",
    "        ux = []\n",
    "        uxx = []\n",
    "        \n",
    "        for i in range(self.ne):\n",
    "            \n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                # Watch variables representing t and x during this GradientTape\n",
    "                tape.watch(x)\n",
    "\n",
    "                # Compute current values u(t,x)\n",
    "                u.append(self.NNs[i](x)[:, 0])\n",
    "                ux.append(tape.gradient(u[i], x)[:, 0])\n",
    "                \n",
    "            uxx.append(tape.gradient(ux[i], x)[:, 0])\n",
    "            \n",
    "            del tape\n",
    "                \n",
    "        return u, ux, uxx\n",
    "\n",
    "    def determine_losses(self):\n",
    "        \n",
    "        # Short-hand notation of mean-squared loss\n",
    "        mse = lambda x : tf.reduce_mean(tf.square(x))\n",
    "        #mse = lambda x : tf.reduce_sum(tf.square(x))\n",
    "\n",
    "        \n",
    "        ###################################\n",
    "        ### Residual loss for all edges ###\n",
    "        ###################################\n",
    "        u, ux, uxx = self._fvals2(self.x)\n",
    "        \n",
    "        loss_res = 0\n",
    "        for i in range(self.ne):\n",
    "            #res_e = u[i] - self.U[i][self.idx-1, :] + self.dt * pde(u[i], 0., ux[i], uxx[i])\n",
    "            #print(u[i])\n",
    "            res_e = u[i] - self.uold[i] + self.dt * pde(u[i], 0., ux[i], uxx[i])\n",
    "\n",
    "            #print(self.U[i][self.idx-1, :])\n",
    "            #loss_res += mse(res_e[1:-1])\n",
    "            loss_res += mse(res_e)\n",
    "\n",
    "            #print(mse(res_e))\n",
    "            #print(self.U[i][self.idx-1, :])\n",
    "        \n",
    "        ###################################\n",
    "        ###   Continuity in vertices    ###\n",
    "        ###################################\n",
    "        \n",
    "        # ul, ult, ulx = self._fvals1(self.Xl[:,0], self.Xl[:,1])\n",
    "        # uu, uut, uux = self._fvals1(self.Xu[:,0], self.Xu[:,1])\n",
    "        loss_cont = 0\n",
    "        \n",
    "        for i, v in enumerate(self.graph.innerVertices):\n",
    "            \n",
    "            for j in self.graph.Vin[v]:\n",
    "                val = u[j][-1] - self.vertexVals[i]\n",
    "                loss_cont += mse(val)\n",
    "\n",
    "            for j in self.graph.Vout[v]:\n",
    "                val = u[j][0] - self.vertexVals[i]\n",
    "                loss_cont += mse(val)\n",
    "                \n",
    "        #####################################\n",
    "        ### Kirchhoff-Neumann in vertices ###\n",
    "        #####################################\n",
    "        \n",
    "        # Kirchhoff-Neumann condition in center nodes\n",
    "        loss_KN = 0\n",
    "        for i in self.graph.innerVertices:\n",
    "            \n",
    "            val = 0\n",
    "            #print('Kirchhoff-Neumann in node ', i)\n",
    "            for j in self.graph.Vin[i]:\n",
    "                #print('incoming edge:', j)\n",
    "                val += flux(u[j][-1], ux[j][-1])\n",
    "                #val += flux(uu[j], uux[j])\n",
    "                \n",
    "            for j in self.graph.Vout[i]:\n",
    "                #print('outgoing edge:', j)\n",
    "                val -= flux(u[j][0], ux[j][0])\n",
    "                #val -= flux(ul[j], ulx[j])\n",
    "            loss_KN += mse(val)\n",
    "        \n",
    "        #####################################\n",
    "        ###      Inflow/Outflow conds     ###\n",
    "        #####################################\n",
    "        \n",
    "        loss_D = 0\n",
    "        for i, v in enumerate(self.graph.dirichletNodes):\n",
    "            \n",
    "            #TODO\n",
    "            alpha = self.graph.dirichletAlpha[v]\n",
    "            beta = self.graph.dirichletBeta[v]\n",
    "            \n",
    "            print('\\nin node ', v, 'alpha ', alpha, 'beta ', beta)\n",
    "            val = 0\n",
    "            #print('\\n', val)\n",
    "            for j in self.graph.Vin[v]:\n",
    "                print('outflow: ', j)\n",
    "                #val += -flux(uu[j], uux[j]) - beta * (uu[j])\n",
    "                val += flux(u[j][-1], ux[j][-1]) - beta * (u[j][-1])\n",
    "                #loss_D += mse(val)\n",
    "            #print(val)\n",
    "                \n",
    "\n",
    "            for j in self.graph.Vout[v]:\n",
    "                print('inflow: ', j)\n",
    "                #val += -flux(ul[j], ulx[j]) + alpha * (1-ul[j])\n",
    "                val += -flux(u[j][0], ux[j][0]) + alpha * (1.-u[j][0])\n",
    "                #val += -flux(ul[j], ulx[j]) + alpha * (1-ul[j])\n",
    "                #loss_D += mse(val)\n",
    "            #print(val, '\\n')\n",
    "            loss_D += mse(val)\n",
    "            \n",
    "        return loss_res, loss_cont, loss_KN, loss_D\n",
    "    \n",
    "    def loss_fn(self):\n",
    "        \n",
    "        loss_res, loss_cont, loss_KN, loss_D = self.determine_losses()\n",
    "        \n",
    "        loss = loss_res + loss_cont + loss_KN + loss_D\n",
    "        #print(loss_res)\n",
    "        #print(loss_cont)\n",
    "        #print(loss_KN)\n",
    "        #print(loss_D)\n",
    "        #print(loss)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def get_grad(self):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # This tape is for derivatives with\n",
    "            # respect to trainable variables\n",
    "            tape.watch(self.trainable_variables)\n",
    "            loss = self.loss_fn()\n",
    "\n",
    "        g = tape.gradient(loss, self.trainable_variables)\n",
    "        del tape\n",
    "\n",
    "        return loss, g\n",
    "    \n",
    "    \n",
    "            \n",
    "    def solve_with_TFoptimizer(self, optimizer, eps, N=1001):\n",
    "        \"\"\"This method performs a gradient descent type optimization.\"\"\"\n",
    "        \n",
    "        self.callback_init()\n",
    "        \n",
    "        for i in range(N):\n",
    "            loss, g = self.get_grad()\n",
    "            # Perform gradient descent step\n",
    "            for j in range(self.nvar):\n",
    "                optimizer.apply_gradients(zip(g[j], self.trainable_variables[j]))\n",
    "            #print(self.current_loss)\n",
    "            self.current_loss = loss.numpy()\n",
    "            #print(self.current_loss)\n",
    "            #print(loss)\n",
    "            #print('\\n')\n",
    "\n",
    "            self.callback()\n",
    "            \n",
    "            if self.current_loss < eps:\n",
    "                break\n",
    "                \n",
    "    def solve_with_ScipyOptimizer(self, method='L-BFGS-B', **kwargs):\n",
    "        \"\"\"This method provides an interface to solve the learning problem\n",
    "        using a routine from scipy.optimize.minimize.\n",
    "        (Tensorflow 1.xx had an interface implemented, which is not longer\n",
    "        supported in Tensorflow 2.xx.)\n",
    "        Type conversion is necessary since scipy-routines are written in\n",
    "        Fortran which requires 64-bit floats instead of 32-bit floats.\"\"\"\n",
    "\n",
    "        def get_weight_tensor():\n",
    "            \"\"\"Function to return current variables of the model\n",
    "            as 1d tensor as well as corresponding shapes as lists.\"\"\"\n",
    "\n",
    "            weight_list = []\n",
    "            shape_list = []\n",
    "\n",
    "            # Loop over all variables, i.e. weight matrices, bias vectors\n",
    "            # and unknown parameters\n",
    "            for i in range(len(self.trainable_variables)):\n",
    "                for v in self.trainable_variables[i]:\n",
    "                    shape_list.append(v.shape)\n",
    "                    weight_list.extend(v.numpy().flatten())\n",
    "\n",
    "            weight_list = tf.convert_to_tensor(weight_list)\n",
    "            return weight_list, shape_list\n",
    "\n",
    "\n",
    "        x0, shape_list = get_weight_tensor()\n",
    "\n",
    "        def set_weight_tensor(weight_list):\n",
    "            \"\"\"Function which sets list of weights\n",
    "            to variables in the model.\"\"\"\n",
    "            idx = 0\n",
    "\n",
    "            for i in range(len(self.trainable_variables)):\n",
    "                for v in self.trainable_variables[i]:\n",
    "                    vs = v.shape\n",
    "\n",
    "                    # Weight matrices\n",
    "                    if len(vs) == 2:\n",
    "                        sw = vs[0] * vs[1]\n",
    "                        new_val = tf.reshape(\n",
    "                            weight_list[idx:idx + sw], (vs[0], vs[1]))\n",
    "                        idx += sw\n",
    "\n",
    "                    # Bias vectors\n",
    "                    elif len(vs) == 1:\n",
    "                        new_val = weight_list[idx:idx+vs[0]]\n",
    "                        idx += vs[0]\n",
    "\n",
    "                    # Variables (in case of parameter identification setting)\n",
    "                    elif len(vs) == 0:\n",
    "                        new_val = weight_list[idx]\n",
    "                        idx += 1\n",
    "\n",
    "                    # Assign variables (Casting necessary since scipy requires float64 type)\n",
    "                    v.assign(tf.cast(new_val, DTYPE))\n",
    "\n",
    "        def get_loss_and_grad(w):\n",
    "            \"\"\"Function that provides current loss and gradient\n",
    "            w.r.t the trainable variables as vector. This is mandatory\n",
    "            for the LBFGS minimizer from tfp.optimizer.\"\"\"\n",
    "\n",
    "            # Update weights in model\n",
    "            set_weight_tensor(w)\n",
    "            # Determine value of \\phi and gradient w.r.t. \\theta at w\n",
    "            loss, grad = self.get_grad()\n",
    "            # Flatten gradient\n",
    "            grad_flat = []\n",
    "            for i in range(len(self.trainable_variables)):\n",
    "                for g in grad[i]:\n",
    "                    grad_flat.extend(g.numpy().flatten())\n",
    "\n",
    "            # Store current loss for callback function\n",
    "            #print(self.current_loss)\n",
    "            self.current_loss = loss\n",
    "            #print(self.current_loss)\n",
    "\n",
    "            # Return value and gradient of \\phi as tuple\n",
    "            return loss.numpy().astype(np.float64), np.array(grad_flat, dtype=np.float64)\n",
    "\n",
    "        self.callback_init()\n",
    "\n",
    "        return scipy.optimize.minimize(fun=get_loss_and_grad,\n",
    "                                       x0=x0,\n",
    "                                       jac=True,\n",
    "                                       method=method,\n",
    "                                       callback=self.callback,\n",
    "                                       **kwargs)\n",
    "    \n",
    "                \n",
    "    def ts_scheme(self, eps=1e-6):\n",
    "        max_trials = 1\n",
    "        while self.idx < 20: #self.nt:\n",
    "            print('Solve time step {}/{}\\n'.format(self.idx, self.nt))\n",
    "            \n",
    "            trial = 0\n",
    "            while trial < max_trials:\n",
    "                \n",
    "                print('Adam...\\n')\n",
    "                \n",
    "                if self.idx == 1:\n",
    "                    lr = 0.01\n",
    "                    optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                    self.solve_with_TFoptimizer(optim, eps=eps, N=4001)\n",
    "                    \n",
    "                else:\n",
    "                    lr = 0.001\n",
    "                    optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                    self.solve_with_TFoptimizer(optim, eps=eps, N=501)\n",
    "                self.callback(force=True)\n",
    "                print('LBFGS...\\n')\n",
    "                ret = self.solve_with_ScipyOptimizer(options={'maxiter': 50000,\n",
    "                                     'maxfun': 50000,\n",
    "                                     'maxcor': 50,\n",
    "                                     'maxls': 50,\n",
    "                                     'eps': eps,\n",
    "                                     'ftol': 1.0e3*np.finfo(float).eps,\n",
    "                                     'gtol': 1.0e3*np.finfo(float).eps})\n",
    "                # factr is 10000000 \n",
    "                print(ret.message)\n",
    "                trial += 1\n",
    "                self.callback(force=True)\n",
    "            \n",
    "            u = self._fvals0(self.x)\n",
    "            self.assign_u(self.idx, u)\n",
    "            self.idx += 1\n",
    "            self.iter = 0\n",
    "\n",
    "    def assign_u(self, timestep, u):\n",
    "        \n",
    "        for i in range(self.ne):\n",
    "            #print('assign new u to timestep {}'.format(timestep))\n",
    "            #print(u[i].shape)\n",
    "            self.uold[i].assign(u[i])\n",
    "            self.U[i][timestep, :] = u[i]\n",
    "            \n",
    "    def next_step(self):\n",
    "        u = self._fvals0(self.x)\n",
    "        self.assign_u(self.idx, u)\n",
    "        self.idx += 1\n",
    "\n",
    "        \n",
    "    def callback_init(self):\n",
    "        self.t0 = time()\n",
    "        print(' Iter            Loss    Time')\n",
    "        print('-----------------------------')\n",
    "    \n",
    "    def callback(self, xr=None, force=False):\n",
    "        if self.iter % 100 == 0 or force:\n",
    "            print('{:05d}  {:10.8e}   {:4.2f}'.format(\n",
    "                self.iter, self.current_loss, time() - self.t0))\n",
    "        self.hist.append(self.current_loss)\n",
    "        self.iter += 1\n",
    "        \n",
    "    def plot_loss_history(self, ax=None):\n",
    "        if not ax:\n",
    "            fig = plt.figure(figsize=(7, 5))\n",
    "            ax = fig.add_subplot(111)\n",
    "        ax.semilogy(range(len(self.hist)), self.hist, 'k-')\n",
    "        ax.set_xlabel('$n_{epoch}$')\n",
    "        ax.set_ylabel('$\\\\phi^{n_{epoch}}$')\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 5 neural nets.\n",
      "\n",
      "in node  0 alpha  0.9 beta  0.0\n",
      "inflow:  0\n",
      "\n",
      "in node  1 alpha  0.3 beta  0.0\n",
      "inflow:  1\n",
      "\n",
      "in node  4 alpha  0.0 beta  0.8\n",
      "outflow:  3\n",
      "\n",
      "in node  5 alpha  0.0 beta  0.1\n",
      "outflow:  4\n",
      "Solve time step 1/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "\n",
      "in node  0 alpha  0.9 beta  0.0\n",
      "inflow:  0\n",
      "\n",
      "in node  1 alpha  0.3 beta  0.0\n",
      "inflow:  1\n",
      "\n",
      "in node  4 alpha  0.0 beta  0.8\n",
      "outflow:  3\n",
      "\n",
      "in node  5 alpha  0.0 beta  0.1\n",
      "outflow:  4\n",
      "00000  2.09564450e+00   2.71\n",
      "00100  3.29135123e-03   5.40\n",
      "00200  1.71436868e-03   7.94\n",
      "00300  7.83624002e-04   10.51\n",
      "00400  5.00135109e-04   12.97\n",
      "00500  4.05846376e-03   15.28\n",
      "00600  1.07753412e-03   17.72\n",
      "00700  7.59984292e-04   20.25\n",
      "00800  3.12638811e-04   22.79\n",
      "00900  5.39559215e-04   25.28\n",
      "01000  2.59170742e-04   27.88\n",
      "01100  4.59557129e-04   30.42\n",
      "01200  3.70064615e-04   32.90\n",
      "01300  1.82346836e-04   35.37\n",
      "01400  1.91510583e-04   38.31\n",
      "01500  1.79122770e-04   40.92\n",
      "01600  1.82415057e-04   43.84\n",
      "01700  2.59659562e-04   46.83\n",
      "01800  1.16504266e-03   49.40\n",
      "01900  1.15951875e-04   52.20\n",
      "02000  8.84008051e-05   54.68\n",
      "02100  1.16486644e-04   57.13\n",
      "02200  1.11655594e-04   59.94\n",
      "02300  7.49942867e-04   62.84\n",
      "02400  1.57100212e-04   65.50\n",
      "02500  1.33550261e-04   68.14\n",
      "02600  4.61524668e-05   70.84\n",
      "02700  8.41209896e-05   73.25\n",
      "02800  6.14424695e-05   75.81\n",
      "02900  4.58767552e-04   78.35\n",
      "03000  1.12028576e-04   80.95\n",
      "03100  1.76260650e-04   83.53\n",
      "03200  7.61534090e-05   86.03\n",
      "03300  1.50671535e-04   88.52\n",
      "03400  9.96205813e-05   91.05\n",
      "03500  6.54762858e-05   93.61\n",
      "03600  5.99581784e-05   96.29\n",
      "03700  3.17124230e-05   98.84\n",
      "03800  1.28561485e-04   101.49\n",
      "03900  8.30532230e-04   104.21\n",
      "04000  2.60042716e-05   107.04\n",
      "04001  2.60042716e-05   107.04\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "04100  3.52175024e-06   3.21\n",
      "04200  6.60471161e-07   6.76\n",
      "04300  1.72814944e-07   10.41\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "04350  1.67650867e-07   12.04\n",
      "Solve time step 2/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  1.71299707e-03   0.12\n",
      "00100  2.57225759e-05   3.19\n",
      "00200  1.14168796e-05   5.65\n",
      "00300  9.48659089e-06   8.22\n",
      "00400  8.04442265e-06   10.74\n",
      "00500  6.91519823e-06   13.22\n",
      "00501  6.91519823e-06   13.22\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00600  1.33288581e-06   2.53\n",
      "00700  6.03653983e-07   5.69\n",
      "00800  5.35452175e-07   8.69\n",
      "00900  5.17947673e-07   11.74\n",
      "01000  3.24267349e-07   14.73\n",
      "01100  2.45880507e-07   17.75\n",
      "01200  1.39226612e-07   20.92\n",
      "01300  1.17039211e-07   23.90\n",
      "01400  1.05147606e-07   26.52\n",
      "01500  9.60915416e-08   29.64\n",
      "01600  7.94317312e-08   32.65\n",
      "01700  7.07690282e-08   35.68\n",
      "01800  6.72317637e-08   38.49\n",
      "01900  6.11917057e-08   41.72\n",
      "02000  5.84645539e-08   44.68\n",
      "02100  5.55505770e-08   47.85\n",
      "02200  4.96934915e-08   51.07\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "02292  2.55556882e-08   54.11\n",
      "Solve time step 3/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  4.96009728e-04   0.10\n",
      "00100  1.17215568e-06   3.11\n",
      "00113  9.91406444e-07   3.47\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00200  6.48582276e-08   2.52\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00244  8.93585060e-09   3.85\n",
      "Solve time step 4/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  2.96954207e-04   0.11\n",
      "00056  8.99507871e-07   1.79\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  6.61307976e-08   1.60\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00143  1.17858605e-08   2.98\n",
      "Solve time step 5/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  2.12900921e-04   0.10\n",
      "00054  5.48770400e-07   1.70\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  3.30496126e-08   1.26\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00148  8.68905061e-09   2.47\n",
      "Solve time step 6/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  1.66504818e-04   0.08\n",
      "00050  7.92935328e-07   1.42\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  2.30848084e-08   1.53\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00135  1.34586487e-08   2.59\n",
      "Solve time step 7/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  1.37094621e-04   0.11\n",
      "00046  3.98391818e-07   1.47\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.97827949e-08   1.66\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00121  1.37440375e-08   2.24\n",
      "Solve time step 8/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  1.16809192e-04   0.11\n",
      "00042  7.85770676e-07   1.29\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  2.04285136e-08   1.48\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00114  1.48441228e-08   1.81\n",
      "Solve time step 9/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  1.01955009e-04   0.08\n",
      "00039  8.71293385e-07   1.10\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00098  1.59495397e-08   1.58\n",
      "Solve time step 10/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  9.06135973e-05   0.09\n",
      "00038  9.96312620e-07   1.10\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.81143340e-08   1.85\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00120  1.46996711e-08   2.38\n",
      "Solve time step 11/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  8.16626397e-05   0.10\n",
      "00035  4.15825863e-07   1.14\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.89505723e-08   1.62\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00132  1.22704916e-08   2.39\n",
      "Solve time step 12/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  7.44041293e-05   0.09\n",
      "00041  4.33010550e-07   1.11\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.69975901e-08   1.60\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00118  1.46290908e-08   2.09\n",
      "Solve time step 13/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  6.84082460e-05   0.09\n",
      "00038  8.81160854e-07   1.07\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.83829944e-08   1.68\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00142  1.08187798e-08   2.73\n",
      "Solve time step 14/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  6.33519706e-05   0.08\n",
      "00032  8.83079978e-07   0.86\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.32034329e-08   1.63\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00109  1.25783288e-08   1.83\n",
      "Solve time step 15/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  5.90466847e-05   0.09\n",
      "00044  9.76874085e-07   1.12\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.52807537e-08   1.26\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00103  1.52773041e-08   1.31\n",
      "Solve time step 16/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  5.53282986e-05   0.08\n",
      "00041  4.94385271e-07   1.04\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.77377060e-08   1.36\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00104  1.77003573e-08   1.42\n",
      "Solve time step 17/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  5.20876398e-05   0.08\n",
      "00035  4.75208261e-07   0.91\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  1.64440039e-08   1.50\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00150  7.38293285e-09   2.70\n",
      "Solve time step 18/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  4.92157383e-05   0.08\n",
      "00044  6.69795270e-07   1.17\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  9.84397314e-09   1.27\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00103  9.84058250e-09   1.31\n",
      "Solve time step 19/1001\n",
      "\n",
      "Adam...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00000  4.66823243e-05   0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00038  8.83424536e-07   1.13\n",
      "LBFGS...\n",
      "\n",
      " Iter            Loss    Time\n",
      "-----------------------------\n",
      "00100  9.83199145e-09   1.30\n",
      "b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "00156  5.84052464e-09   2.54\n",
      "CPU times: user 9min 2s, sys: 19.2 s, total: 9min 21s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "#gPINN = GraphPINN(A, dirichletNodes, dirichletAlpha, dirichletBeta, lb, ub)\n",
    "solver = TimesteppingPINNSolver(graph, t_r, x_r)\n",
    "solver.determine_losses()\n",
    "#1.0*np.finfo(float).eps\n",
    "#u0 = solver._fvals0(x_r)\n",
    "#u1, u1x = solver._fvals1(x_r)\n",
    "#u2, u2x, u2xx = solver._fvals2(x_r)\n",
    "#print(u1)\n",
    "#print(u1x)\n",
    "#print([u2[i]-u0[i] for i in range(gPINN.ne)])\n",
    "#print([u2x[i]-u1x[i] for i in range(gPINN.ne)])\n",
    "#print(u2xx)\n",
    "#solver.determine_losses()\n",
    "\n",
    "#lr = 0.01\n",
    "#optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "#print('Start with TF optimizer\\n')\n",
    "#solver.solve_with_TFoptimizer(optim, N=5001)\n",
    "solver.ts_scheme(1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "in node  0 alpha  0.7 beta  0.0\n",
      "inflow:  0\n",
      "\n",
      "in node  1 alpha  0.0 beta  0.8\n",
      "outflow:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.4421223184174575e-08>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wall time: 7min 53s\n",
    "# Wall time: 1min 6s\n",
    "\n",
    "\n",
    "#solver.determine_losses()\n",
    "solver.loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03012ef3e7644ec0adf29ff60b04904e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd2b1af4ea94c28a513ca4d41c2c1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='j', max=1000), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#Nt = 60\n",
    "#Nx = 120\n",
    "\n",
    "#tspace = tf.linspace(lb[0], ub[0], Nt + 1)\n",
    "#xspace = tf.reshape(tf.linspace(lb[1], ub[1], Nx + 1), [-1, 1])\n",
    "\n",
    "pos = solver.graph.pos\n",
    "xy_list = [pos[e[0]] + x_r*(pos[e[1]] - pos[e[0]]) / (ub[1]-lb[1]) for e in solver.graph.E]\n",
    "\n",
    "def plot_network(j=0, fig=None):\n",
    "    if not fig:\n",
    "        fig = plt.figure(1, clear=True)\n",
    "    else:\n",
    "        fig.clf()\n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "    \n",
    "    for i, e in enumerate(solver.graph.E):\n",
    "        u = solver.U[i][j, :]\n",
    "        ax.plot(xy_list[i][:,0], xy_list[i][:,1], u)\n",
    "    \n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlim([.0,1.0])\n",
    "    ax.view_init(12, 135)\n",
    "\n",
    "#fig.canvas.layout.width = '100%'\n",
    "#fig.canvas.layout.height = '900px'\n",
    "j_slider = widgets.IntSlider(min=0,max=N_b,step=1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "def interactive_net(j=0):\n",
    "    plot_network(j, fig)\n",
    "    \n",
    "interactive_plot = interactive(interactive_net, j=j_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "#output.layout.height = '350px'\n",
    "interactive_plot\n",
    "#u = plot_network(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '1600x1000', '-pix_fmt', 'rgba', '-r', '15', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'h264', '-pix_fmt', 'yuv420p', '-b', '1800k', '-metadata', 'artist=Jan Blechschmidt', '-y', 'sol_pinn.mp4']' returned non-zero exit status 255.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;31m# TODO: See if turning off blit is really necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                     \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_next_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mprogress_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_draw_next_frame\u001b[0;34m(self, framedata, blit)\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframedata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframedata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_post_draw\u001b[0;34m(self, framedata, blit)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1863\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1864\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;31m# Then rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/mpl_toolkits/mplot3d/art3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mxs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verts3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36mproj_transform\u001b[0;34m(xs, ys, zs, M)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vec_pad_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_proj_transform_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36m_vec_pad_ones\u001b[0;34m(xs, ys, zs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_vec_pad_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6929\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6930\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6931\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1000\u001b[0m                                                   stack(strides))\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m def _constant_impl(\n\u001b[0m\u001b[1;32m    268\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-3b7cbe305dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mline_ani\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mline_ani\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sol_pinn.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#fig2 = plt.figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;34m\"\"\"Finish any processing for writing the movie.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             raise subprocess.CalledProcessError(\n\u001b[0;32m--> 391\u001b[0;31m                 self._proc.returncode, self._proc.args, out, err)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '1600x1000', '-pix_fmt', 'rgba', '-r', '15', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'h264', '-pix_fmt', 'yuv420p', '-b', '1800k', '-metadata', 'artist=Jan Blechschmidt', '-y', 'sol_pinn.mp4']' returned non-zero exit status 255."
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "#def update_line(num, data, line):\n",
    "#    line.set_data(data[..., :num])\n",
    "#    return line,\n",
    "\n",
    "# Set up formatting for the movie files\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Jan Blechschmidt'), bitrate=1800)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "line_ani = animation.FuncAnimation(fig, interactive_net, 200, interval=50)\n",
    "line_ani.save('sol_pinn.mp4', writer=writer)\n",
    "\n",
    "#fig2 = plt.figure()\n",
    "\n",
    "#x = np.arange(-9, 10)\n",
    "#y = np.arange(-9, 10).reshape(-1, 1)\n",
    "#base = np.hypot(x, y)\n",
    "#ims = []\n",
    "#for add in np.arange(15):\n",
    "#    ims.append((plt.pcolor(x, y, base + add, norm=plt.Normalize(0, 30)),))\n",
    "\n",
    "#im_ani = animation.ArtistAnimation(fig2, ims, interval=50, repeat_delay=3000,\n",
    "#                                   blit=True)\n",
    "#im_ani.save('im.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
