{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7417d936",
   "metadata": {},
   "source": [
    "# First and second derivative of FNN with respect to input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90e9a5",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a899b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12c0bb",
   "metadata": {},
   "source": [
    "Define activation function and its derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "babdbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mσ(x):\n",
    "    return np.abs(x) + np.log(1. + np.exp(-2. * np.abs(x)))\n",
    "        \n",
    "        \n",
    "def mdσ(x):\n",
    "    return np.tanh(x)\n",
    "    \n",
    "    \n",
    "def md2σ(x):\n",
    "    return np.divide(1., np.square(np.cosh(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9dfa6983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.]\n",
      " [20.]\n",
      " [30.]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[8.24461446e-09]\n",
      " [1.69934170e-17]\n",
      " [3.50260431e-26]]\n"
     ]
    }
   ],
   "source": [
    "x = [[10], [20], [30]]\n",
    "\n",
    "print(mσ(x))\n",
    "print(mdσ(x))\n",
    "print(md2σ(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5b1e1",
   "metadata": {},
   "source": [
    "Does not exactly match the results/values in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be001141",
   "metadata": {},
   "source": [
    "Define Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d7700d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class PINN(tf.keras.Model):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_dim=1,\n",
    "                 num_hidden_layers=4,\n",
    "                 num_neurons_per_layer=20,\n",
    "                 activation= mσ,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.input_dim = 2\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Define NN architecture\n",
    "        \n",
    "        # Inititialize num_hidden_layers many fully connected dense layers\n",
    "        self.hidden = [tf.keras.layers.Dense(num_neurons_per_layer,\n",
    "                                             activation = activation,\n",
    "                                             kernel_initializer=kernel_initializer) for _ in range(self.num_hidden_layers)]\n",
    "        \n",
    "        # Output layer\n",
    "        #self.out = tf.keras.layers.Dense(output_dim, activation=None)\n",
    "        self.out = tf.keras.layers.Dense(output_dim, activation = activation)\n",
    "        \n",
    "    def call(self, X):\n",
    "        \"\"\"Forward-pass through neural network.\"\"\"\n",
    "        self.tmp_layer_output = []\n",
    "        #Z = self.scale(X)\n",
    "        Z = X\n",
    "        self.tmp_layer_output.append(Z)\n",
    "        \n",
    "        for i in range(self.num_hidden_layers):\n",
    "            Z = self.hidden[i](Z)\n",
    "            self.tmp_layer_output.append(Z)\n",
    "            \n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88587d9",
   "metadata": {},
   "source": [
    "Compute gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78803620",
   "metadata": {},
   "source": [
    "Compute gradient for layer l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9fd5f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradientLayer(W,b,a,δ):\n",
    "    z = np.transpose(a @ W)  \n",
    "    b = np.reshape(b, np.shape(z))\n",
    "    z = z + b\n",
    "    \n",
    "    #return W @ np.diag(mdσ(z) * δ)\n",
    "    # return np.diag(mdσ(z) * δ)\n",
    "    return mdσ(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb197a1",
   "metadata": {},
   "source": [
    "Compute gradient of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b270783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient(N):\n",
    "    δ = getGradientLayer(N.out.get_weights()[0], N.out.get_weights()[1], N.tmp_layer_output[-1], np.identity(N.output_dim))\n",
    "\n",
    "    for k in range(N.num_hidden_layers-1, -1, -1):\n",
    "        δ = getGradientLayer(N.hidden[k].get_weights()[0], N.hidden[k].get_weights()[1], N.tmp_layer_output[k], δ)\n",
    "            \n",
    "    return δ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba635ba",
   "metadata": {},
   "source": [
    "Compute gradient and Hessian of last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "798f579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradientHessianLayer(W,b,a,δ):\n",
    "    z = np.transpose(a @ W)  \n",
    "    b = np.reshape(b, np.shape(z))\n",
    "    z = z + b\n",
    "    ϑ = np.diag(md2σ(z).flatten('F'))\n",
    "    \n",
    "    return W @ np.diag(mdσ(z) * δ), W @ ϑ @ np.transpose(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8133f",
   "metadata": {},
   "source": [
    "Compute gradient and Hessian of hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30fc6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradientHessianLayer_hidden(W,b,a,δ,ϑ):\n",
    "    z = np.transpose(a @ W) \n",
    "    b = np.reshape(b, np.shape(z))\n",
    "    z = z + b\n",
    "    \n",
    "    δh = np.reshape(δ, np.shape(md2σ(z)))\n",
    "    t2 = δh * md2σ(z)\n",
    "    H1 = W @ np.diag(t2.flatten('F')) @ np.transpose(W)\n",
    "\n",
    "    dσt = np.diag(mdσ(z).flatten('F'))\n",
    "    t3 = dσt @ ϑ @ dσt\n",
    "    H2 = W @ t3 @ np.transpose(W)\n",
    "    \n",
    "    return W @ np.diag(mdσ(z) * δ), H1+H2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab18966",
   "metadata": {},
   "source": [
    "Compute Hessian and gradient of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d5ad2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHessian(N):\n",
    "    δ,ϑ = getGradientHessianLayer(N.out.get_weights()[0], N.out.get_weights()[1], N.tmp_layer_output[-1], np.identity(N.output_dim))\n",
    "\n",
    "    for k in range(N.num_hidden_layers-1, -1, -1):\n",
    "        δ,ϑ = getGradientHessianLayer_hidden(N.hidden[k].get_weights()[0], N.hidden[k].get_weights()[1], N.tmp_layer_output[k], δ,  ϑ)\n",
    "            \n",
    "    return δ,ϑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5129b90",
   "metadata": {},
   "source": [
    "Why do we get a 2D vector when we insert a 2D vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11139e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0392839]]\n",
      "[0. 0.]\n",
      "[ 0.00301194 -0.003458  ]\n",
      "[[ 0.02138047 -0.00110186]\n",
      " [-0.00110186 -0.03299938]]\n"
     ]
    }
   ],
   "source": [
    "N = PINN()\n",
    "x = tf.Variable([[0.15, 0.1]])\n",
    "#x = tf.constant([[1.]])\n",
    "out = N(x)\n",
    "print(out)\n",
    "#print(N.tmp_layer_output[2])\n",
    "#print(N.hidden[0].get_weights()[0] * x + N.hidden[0].get_weights()[1])\n",
    "#print(mσ(N.hidden[0].get_weights()[0]))\n",
    "#print(np.shape(N.out.get_weights()[0]))\n",
    "#print(np.shape(N.hidden[-1].get_weights()[0]))\n",
    "#print(N.hidden[1].get_weights()[0])\n",
    "δ1 = getGradient(N)\n",
    "δ2,ϑ = getHessian(N)\n",
    "#print(len(N.hidden))\n",
    "#print(N.num_hidden_layers)\n",
    "print(δ1 - δ2)\n",
    "print(δ1)\n",
    "print(ϑ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "27c796cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.3314287 ],\n",
       "        [ 0.45498294],\n",
       "        [ 0.2148701 ],\n",
       "        [-0.42193145],\n",
       "        [-0.5176827 ],\n",
       "        [-0.31287473],\n",
       "        [ 0.3848989 ],\n",
       "        [ 0.4254127 ],\n",
       "        [ 0.324243  ],\n",
       "        [-0.2770318 ],\n",
       "        [-0.422874  ],\n",
       "        [ 0.18879676],\n",
       "        [-0.00179446],\n",
       "        [-0.38508803],\n",
       "        [ 0.25300795],\n",
       "        [-0.44779593],\n",
       "        [ 0.33125246],\n",
       "        [-0.02288008],\n",
       "        [-0.53343976],\n",
       "        [-0.20876151]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.out.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e510d2f",
   "metadata": {},
   "source": [
    "-> We need to choose appropriate dtypes so that no operation overflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c00e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fvals1(N, x):\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(x)\n",
    "        y = N(x)\n",
    "\n",
    "    dy_dx = g.jacobian(y, x)\n",
    "\n",
    "    return y, dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb5aac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#X = tf.random.normal((10,2))\n",
    "#out = N(X[0,:])\n",
    "#print(out)\n",
    "#print(X)\n",
    "#print(getGradient(N))\n",
    "#print(_fvals1(N, X))\n",
    "print(_fvals1(N, x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e968d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fvals2(N, x):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as h:\n",
    "        h.watch(x)\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            y = N(x)\n",
    "\n",
    "        dy_dx = g.jacobian(y, x)\n",
    "    \n",
    "    d2y_d2x = h.gradient(dy_dx, x)\n",
    "\n",
    "    return y, dy_dx, d2y_d2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3998cb0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Target should be a list or nested structure of Tensors or Variables to be differentiated, but recieved None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-9833082daa67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fvals2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-118-2a39bd72d476>\u001b[0m in \u001b[0;36m_fvals2\u001b[1;34m(N, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdy_dx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0md2y_d2x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy_dx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy_dx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md2y_d2x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       raise TypeError(\"Target should be a list or nested structure\"\n\u001b[0m\u001b[0;32m   1051\u001b[0m                       \u001b[1;34m\" of Tensors or Variables to be differentiated,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                       \" but recieved %r\" % (target))\n",
      "\u001b[1;31mTypeError\u001b[0m: Target should be a list or nested structure of Tensors or Variables to be differentiated, but recieved None"
     ]
    }
   ],
   "source": [
    "print(_fvals2(N, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffbf82",
   "metadata": {},
   "source": [
    "Maybe gradient tape thinks that the neural network is not differentiable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f4fec",
   "metadata": {},
   "source": [
    "# Explicit derivatives of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8a110916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_ResNet(tf.keras.Model):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ResNetLayers=2,\n",
    "                 ResNetNeurons=16,\n",
    "                 ResNetStepsize=1.0,\n",
    "                 ResNetActivation='softplus',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(PINN_ResNet, self).__init__(**kwargs)\n",
    "        \n",
    "        #RNact = tf.keras.activations.get(ResNetActivation)\n",
    "        #RNact = my_act\n",
    "        RNact = mσ\n",
    "        \n",
    "\n",
    "        \n",
    "        self.ResNetLayers = ResNetLayers\n",
    "        self.ResNetStepsize = ResNetStepsize\n",
    "\n",
    "        self.ResNet = [tf.keras.layers.Dense(ResNetNeurons,\n",
    "                                        activation = RNact) for _ in range(self.ResNetLayers)]\n",
    "        self.wb = tf.keras.layers.Dense(1)\n",
    "        self.A = tf.keras.layers.Dense(2, use_bias=False)\n",
    "        self.c = tf.keras.layers.Dense(1, use_bias=False)\n",
    "        \n",
    "        #self.num_hidden_layers = num_hidden_layers\n",
    "        self.input_dim = 2\n",
    "        self.output_dim = 1\n",
    "\n",
    "\n",
    "        # Define NN architecture\n",
    "        \n",
    "        # Output layer\n",
    "        #self.out = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        \"\"\"Forward-pass through neural network.\"\"\"\n",
    "        self.tmp_layer_output = [input_tensor]\n",
    "        N = self.ResNet[0](input_tensor, training=training)\n",
    "        self.tmp_layer_output.append(N)\n",
    "        for i in range(1, self.ResNetLayers):\n",
    "            N = N + self.ResNetStepsize * self.ResNet[i](N, training=training)\n",
    "            self.tmp_layer_output.append(N)\n",
    "        Phi = self.wb(N, training=training)\n",
    "        #print(input_tensor)\n",
    "        As = self.A(input_tensor, training=training)\n",
    "        #print(As)\n",
    "        sAs = tf.keras.layers.Dot(axes=(1))([input_tensor, As])\n",
    "        #print(sAs)\n",
    "        Phi += .5 * sAs\n",
    "        #print(Phi.shape)\n",
    "        Phi += self.c(input_tensor, training=training)\n",
    "            \n",
    "        return Phi\n",
    "        #return self.out(Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "96bbecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n",
      "(16, 16)\n"
     ]
    }
   ],
   "source": [
    "Resnet = PINN_ResNet()\n",
    "\n",
    "out = Resnet(x)\n",
    "#print(out)\n",
    "#print(Resnet.tmp_layer_output.append)\n",
    "print(Resnet.wb.get_weights()[0].shape)\n",
    "print(Resnet.ResNet[-1].get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dcc5caae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91068345],\n",
       "       [ 2.4387455 ],\n",
       "       [ 2.3148098 ],\n",
       "       [ 0.30477303],\n",
       "       [-0.5590408 ],\n",
       "       [ 2.088062  ],\n",
       "       [ 1.1690454 ],\n",
       "       [-1.5823517 ],\n",
       "       [-1.3888068 ],\n",
       "       [ 0.21986805],\n",
       "       [ 0.36832523],\n",
       "       [-2.0059075 ],\n",
       "       [-2.500835  ],\n",
       "       [ 2.5938003 ],\n",
       "       [-0.80139565],\n",
       "       [-1.2713152 ]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getGradientLayer(Resnet.ResNet[-1].get_weights()[0], Resnet.ResNet[-1].get_weights()[1], Resnet.tmp_layer_output[-1], Resnet.wb.get_weights()[0])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7e98b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00221908],\n",
       "       [ 0.3507337 ],\n",
       "       [-0.32138073],\n",
       "       [ 0.57655346],\n",
       "       [ 0.5876173 ],\n",
       "       [-0.54192346],\n",
       "       [-0.43655986],\n",
       "       [ 0.09991902],\n",
       "       [-0.20411497],\n",
       "       [ 0.27344877],\n",
       "       [-0.3795122 ],\n",
       "       [ 0.50932956],\n",
       "       [-0.25069582],\n",
       "       [ 0.03257531],\n",
       "       [ 0.29152948],\n",
       "       [ 0.4373746 ]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resnet.wb.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e4248",
   "metadata": {},
   "source": [
    "Attention Attention! We only calculate the gradient of the neural network multiplied by w here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "974d1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient_ResNet(ResNet):\n",
    "    δ = getGradientLayer(ResNet.ResNet[-1].get_weights()[0], ResNet.ResNet[-1].get_weights()[1], ResNet.tmp_layer_output[-1], Resnet.wb.get_weights()[0])\n",
    "    δ = Resnet.wb.get_weights() + ResNet.ResNetStepsize * δ\n",
    " \n",
    "    for k in range(Resnet.ResNetLayers-1, -1, -1):\n",
    "        δ = δ + ResNet.ResNetStepsize * getGradientLayer(ResNet.ResNet[k].get_weights()[0], ResNet.ResNet[k].get_weights()[1], ResNet.ResNet.tmp_layer_output[k], δ)\n",
    "            \n",
    "    return δ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f0cff028",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-0beea8fd0374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetGradient_ResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-129-f5dcded02329>\u001b[0m in \u001b[0;36mgetGradient_ResNet\u001b[1;34m(ResNet)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetGradient_ResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mδ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetGradientLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmp_layer_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mδ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNetStepsize\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mδ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNetLayers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-108-518571a4014a>\u001b[0m in \u001b[0;36mgetGradientLayer\u001b[1;34m(W, b, a, δ)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdσ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mδ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 16)"
     ]
    }
   ],
   "source": [
    "getGradient_ResNet(Resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHessian_ResNet(N):\n",
    "    δ,ϑ = getGradientHessianLayer(N.out.get_weights()[0], N.out.get_weights()[1], N.tmp_layer_output[-1], np.identity(N.output_dim))\n",
    "\n",
    "    for k in range(N.num_hidden_layers-1, -1, -1):\n",
    "        δ,ϑ = getGradientHessianLayer_hidden(N.hidden[k].get_weights()[0], N.hidden[k].get_weights()[1], N.tmp_layer_output[k], δ,  ϑ)\n",
    "            \n",
    "    return δ,ϑ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
