{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7417d936",
   "metadata": {},
   "source": [
    "# First and second derivative of FNN with respect to input (tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90e9a5",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a899b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12c0bb",
   "metadata": {},
   "source": [
    "Define activation function and its derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05776f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom activation function\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "#def mσ(x):\n",
    "    #return np.abs(x) + np.log(1. + np.exp(-2. * np.abs(x)))\n",
    "    \n",
    "def mσ(x):\n",
    "    return tf.math.divide(1, 1 + tf.math.exp(tf.math.negative(x)))\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(mσ)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babdbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mdσ(x):\n",
    "    #return np.tanh(x)\n",
    "    \n",
    "    \n",
    "#def md2σ(x):\n",
    "    #return np.divide(1., np.square(np.cosh(x)))\n",
    "\n",
    "def mdσ(x):\n",
    "    return mσ(x) * (1 - mσ(x))\n",
    "    \n",
    "    \n",
    "def md2σ(x):\n",
    "    return mσ(x) * (1 - mσ(x)) * (1 - 2*mσ(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfa6983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.9999546]\n",
      " [1.       ]\n",
      " [1.       ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.9999546]\n",
      " [1.       ]\n",
      " [1.       ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.5416677e-05]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-4.541255e-05]\n",
      " [-0.000000e+00]\n",
      " [-0.000000e+00]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = [[10.], [20.], [30.]]\n",
    "\n",
    "print(mσ(x))\n",
    "print(tf.keras.activations.sigmoid(x))\n",
    "print(mdσ(x))\n",
    "print(md2σ(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5b1e1",
   "metadata": {},
   "source": [
    "Does not exactly match the results/values in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be001141",
   "metadata": {},
   "source": [
    "Define Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7700d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class PINN(tf.keras.Model):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_dim=1,\n",
    "                 num_hidden_layers=3,\n",
    "                 num_neurons_per_layer=20,\n",
    "                 activationfunction = 'sigmoid',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.input_dim = 2\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Define NN architecture\n",
    "        \n",
    "        # Inititialize num_hidden_layers many fully connected dense layers\n",
    "        self.hidden = [tf.keras.layers.Dense(num_neurons_per_layer,\n",
    "                                             activation = activationfunction,\n",
    "                                             kernel_initializer=kernel_initializer) for _ in range(self.num_hidden_layers)]\n",
    "        \n",
    "        # Output layer\n",
    "        #self.out = tf.keras.layers.Dense(output_dim, activation=None)\n",
    "        self.out = tf.keras.layers.Dense(output_dim, activation = activationfunction)\n",
    "        \n",
    "    def call(self, X):\n",
    "        \"\"\"Forward-pass through neural network.\"\"\"\n",
    "        self.tmp_layer_output = []\n",
    "        #Z = self.scale(X)\n",
    "        Z = X\n",
    "        self.tmp_layer_output.append(Z)\n",
    "        \n",
    "        for i in range(self.num_hidden_layers):\n",
    "            Z = self.hidden[i](Z)\n",
    "            self.tmp_layer_output.append(Z)\n",
    "            \n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88587d9",
   "metadata": {},
   "source": [
    "Compute gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78803620",
   "metadata": {},
   "source": [
    "Compute gradient for layer l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd5f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_layer(W,b,a,δ):\n",
    "    z1 = tf.transpose(a @ W)  \n",
    "    b = tf.reshape(b, z1.shape)\n",
    "    z2 = z1 + b\n",
    "    z3 = mdσ(z2) * δ\n",
    "    \n",
    "    return W @ z3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb197a1",
   "metadata": {},
   "source": [
    "Compute gradient of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b270783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(N, x):\n",
    "    output = N(tf.reshape(x, (1,2)))\n",
    "    δ = get_gradient_layer(N.out.weights[0], N.out.weights[1], N.tmp_layer_output[-1], np.identity(N.output_dim))\n",
    "\n",
    "    for k in range(N.num_hidden_layers-1, -1, -1):\n",
    "        δ = get_gradient_layer(N.hidden[k].weights[0], N.hidden[k].weights[1], N.tmp_layer_output[k], δ)\n",
    "            \n",
    "    return output, δ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4b1001",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() got an unexpected keyword argument 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e712fbb112a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mNeuralN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmp_layer_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'activation'"
     ]
    }
   ],
   "source": [
    "NeuralN = PINN()\n",
    "x = tf.random.normal((1,2))\n",
    "out = NeuralN(x)\n",
    "NeuralN.out(NeuralN.tmp_layer_output[-1], activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7f5b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.42232913]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00079764 -0.00086041 -0.00088197 -0.00080512 -0.00085263 -0.00079898\n",
      "  -0.00082354 -0.0008866  -0.00086769 -0.00076101 -0.00088837 -0.00084809\n",
      "  -0.00082906 -0.00087621 -0.00081441 -0.00080699 -0.0008009  -0.00089831\n",
      "  -0.00089284 -0.00081822]\n",
      " [ 0.00128271  0.00138364  0.00141832  0.00129473  0.00137114  0.00128486\n",
      "   0.00132436  0.00142576  0.00139535  0.0012238   0.00142861  0.00136383\n",
      "   0.00133323  0.00140905  0.00130967  0.00129774  0.00128794  0.0014446\n",
      "   0.00143579  0.0013158 ]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.24979737]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.00034369  0.00032241  0.00031717  0.00032634  0.000335    0.0003471\n",
      "   0.00031634  0.0003471   0.00031208  0.00034705  0.00031395  0.00033835\n",
      "   0.00030499  0.00032666  0.00035989  0.00031406  0.00031431  0.00034782\n",
      "   0.0003465   0.00034254]\n",
      " [-0.00099104 -0.00092967 -0.00091458 -0.00094102 -0.00096598 -0.00100088\n",
      "  -0.00091217 -0.00100086 -0.00089988 -0.00100073 -0.00090527 -0.00097564\n",
      "  -0.00087944 -0.00094192 -0.00103776 -0.0009056  -0.00090633 -0.00100295\n",
      "  -0.00099914 -0.00098774]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.7961149]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.13544906e-04  1.17971264e-04  1.03603918e-04  1.11973932e-04\n",
      "   1.11098067e-04  1.11354610e-04  1.10959940e-04  1.11250505e-04\n",
      "   1.09949855e-04  1.05879124e-04  1.05066625e-04  1.07521962e-04\n",
      "   1.05378815e-04  1.10184876e-04  1.07590982e-04  1.14339673e-04\n",
      "   1.03633232e-04  1.06119725e-04  1.09979002e-04  1.05108178e-04]\n",
      " [-5.91337739e-05 -6.14392047e-05 -5.39564644e-05 -5.83156652e-05\n",
      "  -5.78593754e-05 -5.79929037e-05 -5.77876344e-05 -5.79390035e-05\n",
      "  -5.72615245e-05 -5.51413686e-05 -5.47184027e-05 -5.59970504e-05\n",
      "  -5.48811804e-05 -5.73837897e-05 -5.60330809e-05 -5.95475431e-05\n",
      "  -5.39718021e-05 -5.52668062e-05 -5.72768040e-05 -5.47401141e-05]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.5508115]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-9.5302821e-05 -9.2787421e-05 -9.7052005e-05 -9.7562210e-05\n",
      "  -8.8684334e-05 -9.6837102e-05 -8.2865707e-05 -8.7854132e-05\n",
      "  -9.8057819e-05 -8.7192864e-05 -9.5121446e-05 -9.2492468e-05\n",
      "  -9.3154595e-05 -9.0754518e-05 -9.6347969e-05 -9.0250935e-05\n",
      "  -9.1243346e-05 -9.2971211e-05 -1.0010908e-04 -9.6020332e-05]\n",
      " [ 3.8525788e-04  3.7508924e-04  3.9232837e-04  3.9439055e-04\n",
      "   3.5850325e-04  3.9145944e-04  3.3498104e-04  3.5514636e-04\n",
      "   3.9639484e-04  3.5247416e-04  3.8452464e-04  3.7389767e-04\n",
      "   3.7657353e-04  3.6687110e-04  3.8948262e-04  3.6483601e-04\n",
      "   3.6884801e-04  3.7583263e-04  4.0468707e-04  3.8815860e-04]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.6563805]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00119615 -0.00111025 -0.00133189 -0.0011565  -0.00123299 -0.00109776\n",
      "  -0.0010915  -0.00124394 -0.00122216 -0.00126764 -0.00122151 -0.0011615\n",
      "  -0.0011978  -0.00117718 -0.00126001 -0.0012195  -0.00134026 -0.00116726\n",
      "  -0.00130064 -0.00119891]\n",
      " [ 0.00082245  0.00076339  0.00091578  0.00079519  0.00084778  0.0007548\n",
      "   0.0007505   0.00085531  0.00084034  0.00087161  0.00083989  0.00079863\n",
      "   0.00082359  0.00080941  0.00086636  0.00083851  0.00092154  0.00080259\n",
      "   0.00089429  0.00082435]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.6791775]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.00081707  0.00078779  0.00085612  0.00075541  0.00079673  0.00084024\n",
      "   0.0007822   0.00084888  0.00085225  0.0008336   0.00080079  0.00087848\n",
      "   0.00082973  0.00080932  0.00086047  0.00083564  0.00084501  0.00080682\n",
      "   0.00079553  0.000814  ]\n",
      " [-0.00058255 -0.00056167 -0.00061039 -0.00053859 -0.00056805 -0.00059907\n",
      "  -0.00055769 -0.00060523 -0.00060763 -0.00059433 -0.00057094 -0.00062633\n",
      "  -0.00059158 -0.00057702 -0.00061349 -0.00059579 -0.00060247 -0.00057524\n",
      "  -0.00056719 -0.00058036]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.6219089]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00127093 -0.00117678 -0.00120983 -0.00118306 -0.00122649 -0.00124091\n",
      "  -0.0011602  -0.00117769 -0.00128829 -0.00121234 -0.00123265 -0.00117567\n",
      "  -0.00125637 -0.00125628 -0.00121819 -0.00120589 -0.00122721 -0.00120364\n",
      "  -0.00126491 -0.00114046]\n",
      " [-0.00057807 -0.00053525 -0.00055029 -0.00053811 -0.00055786 -0.00056442\n",
      "  -0.00052771 -0.00053566 -0.00058597 -0.00055142 -0.00056067 -0.00053475\n",
      "  -0.00057145 -0.00057141 -0.00055409 -0.00054849 -0.00055819 -0.00054747\n",
      "  -0.00057534 -0.00051873]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.43627715]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.00247851 0.00241882 0.0023861  0.00247033 0.00242978 0.0022138\n",
      "  0.00240171 0.00248745 0.00241371 0.00229789 0.00247951 0.0023612\n",
      "  0.00234465 0.00223448 0.00248697 0.00223731 0.00237456 0.00244419\n",
      "  0.00254001 0.00218323]\n",
      " [0.00018992 0.00018534 0.00018284 0.00018929 0.00018618 0.00016963\n",
      "  0.00018403 0.0001906  0.00018495 0.00017608 0.00018999 0.00018093\n",
      "  0.00017966 0.00017122 0.00019056 0.00017143 0.00018195 0.00018729\n",
      "  0.00019463 0.00016729]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.37652937]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00073334 -0.00075078 -0.00069556 -0.00067275 -0.00075441 -0.00075758\n",
      "  -0.00063392 -0.000704   -0.00072732 -0.0007222  -0.00076034 -0.00079516\n",
      "  -0.00075927 -0.00072303 -0.00076007 -0.00075848 -0.00069902 -0.00071296\n",
      "  -0.00078922 -0.00074563]\n",
      " [-0.00128953 -0.0013202  -0.0012231  -0.00118299 -0.00132659 -0.00133215\n",
      "  -0.00111471 -0.00123795 -0.00127895 -0.00126996 -0.00133702 -0.00139825\n",
      "  -0.00133513 -0.00127141 -0.00133654 -0.00133374 -0.00122919 -0.00125369\n",
      "  -0.0013878  -0.00131114]], shape=(2, 20), dtype=float32)\n",
      "(20, 1)\n",
      "(20, 20)\n",
      "(20, 20)\n",
      "(2, 20)\n",
      "tf.Tensor([[0.3527241]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00396513 -0.00380701 -0.00360004 -0.00401846 -0.00393673 -0.00401324\n",
      "  -0.0035594  -0.00394577 -0.00391061 -0.00357675 -0.00409213 -0.00374715\n",
      "  -0.00378757 -0.00396504 -0.00388209 -0.00396677 -0.00400036 -0.00391458\n",
      "  -0.00395576 -0.00373631]\n",
      " [ 0.00243798  0.00234076  0.0022135   0.00247077  0.00242051  0.00246756\n",
      "   0.00218851  0.00242608  0.00240445  0.00219918  0.00251606  0.00230395\n",
      "   0.00232881  0.00243792  0.00238692  0.00243899  0.00245964  0.0024069\n",
      "   0.00243221  0.00229729]], shape=(2, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = tf.random.normal((1,2))\n",
    "    NeuralN = PINN()\n",
    "    out, δ1 = get_gradient(NeuralN, x)\n",
    "    #δ_ad = _fvals1(NeuralN, x)[1]\n",
    "    print(out)\n",
    "    print(δ1)\n",
    "    #print(np.linalg.norm(δ1-δ_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69a43e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.601217  ]]\n",
      "\n",
      " [[0.6104211 ]]\n",
      "\n",
      " [[0.6050807 ]]\n",
      "\n",
      " [[0.60368437]]\n",
      "\n",
      " [[0.6006565 ]]\n",
      "\n",
      " [[0.60205907]]\n",
      "\n",
      " [[0.6043431 ]]\n",
      "\n",
      " [[0.60556275]]\n",
      "\n",
      " [[0.60676426]]\n",
      "\n",
      " [[0.6071275 ]]], shape=(10, 1, 1), dtype=float32)\n",
      "[<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
      "array([0.60646474, 0.6061393 , 0.6043411 , 0.6015405 , 0.59705573,\n",
      "       0.6016292 , 0.5986425 , 0.6007536 , 0.60787964, 0.6047025 ,\n",
      "       0.60646474, 0.6061393 , 0.6043411 , 0.6015405 , 0.59705573,\n",
      "       0.6016292 , 0.5986425 , 0.6007536 , 0.60787964, 0.6047025 ],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "elems = tf.random.normal((10,2))\n",
    "#NeuralN(elems)\n",
    "fn = lambda x: get_gradient(NeuralN, x)\n",
    "result = tf.vectorized_map(fn, elems)\n",
    "#r = tf.reshape(result[0], [-1])\n",
    "print(result[0])\n",
    "t = []\n",
    "t.append(r)\n",
    "t.append(r)\n",
    "print([tf.concat(t, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba635ba",
   "metadata": {},
   "source": [
    "Compute gradient and Hessian of last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "798f579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_hessian_last_layer(W,b,a,δ):\n",
    "    z1 = tf.transpose(a @ W)  \n",
    "    b = tf.reshape(b, z1.shape)\n",
    "    z2 = z1 + b\n",
    "    z3 = mdσ(z2) * δ\n",
    "    \n",
    "    ϑ = tf.linalg.diag(tf.reshape(md2σ(z2), [-1]))\n",
    "    \n",
    "    return W @ z3, W @ ϑ @ tf.transpose(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8133f",
   "metadata": {},
   "source": [
    "Compute gradient and Hessian of hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30fc6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_hessian_hidden_layer(W,b,a,δ,ϑ):\n",
    "    z1 = tf.transpose(a @ W)  \n",
    "    b = tf.reshape(b, np.shape(z1))\n",
    "    z2 = z1 + b\n",
    "    z3 = mdσ(z2) * δ\n",
    "    \n",
    "    t2 = δ * md2σ(z2)\n",
    "    H1 = W @ tf.linalg.diag(tf.reshape(t2, [-1])) @ tf.transpose(W)\n",
    "\n",
    "    dσt = tf.linalg.diag(tf.reshape(mdσ(z2), [-1]))\n",
    "    H2 = W @ dσt @ ϑ @ dσt @ tf.transpose(W)\n",
    "    \n",
    "    return W @ z3, H1+H2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab18966",
   "metadata": {},
   "source": [
    "Compute Hessian and gradient of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5ad2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hessian(N, x):\n",
    "    output = N(x)\n",
    "    δ,ϑ = get_gradient_hessian_last_layer(N.out.weights[0], N.out.weights[1], N.tmp_layer_output[-1], np.identity(N.output_dim))\n",
    "\n",
    "    for k in range(N.num_hidden_layers-1, -1, -1):\n",
    "        δ,ϑ = get_gradient_hessian_hidden_layer(N.hidden[k].weights[0], N.hidden[k].weights[1], N.tmp_layer_output[k], δ,  ϑ)\n",
    "      \n",
    "    \n",
    "    return output,δ,ϑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e46c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-4.6592228e-05  1.0044186e-04  5.2424548e-05 -9.6528624e-05\n",
      " -6.0167840e-05  1.3814204e-04  1.0208640e-04  7.0873011e-06\n",
      "  6.1360632e-05 -2.7350346e-05], shape=(10,), dtype=float32)\n",
      "[<tf.Tensor: shape=(80,), dtype=float32, numpy=\n",
      "array([-4.6592228e-05,  6.1558741e-05,  6.1558749e-05, -1.0677885e-04,\n",
      "        1.0044186e-04, -2.2423896e-05, -2.2423899e-05,  6.4172375e-04,\n",
      "        5.2424548e-05, -9.6170006e-05, -9.6169992e-05, -3.8934898e-04,\n",
      "       -9.6528624e-05,  1.3353278e-04,  1.3353277e-04,  9.7017139e-05,\n",
      "       -6.0167840e-05,  5.9802907e-05,  5.9802907e-05, -2.4203377e-04,\n",
      "        1.3814204e-04, -3.6887934e-05, -3.6887948e-05,  6.4006692e-04,\n",
      "        1.0208640e-04, -2.3116154e-05, -2.3116152e-05,  5.8618747e-04,\n",
      "        7.0873011e-06,  5.0335355e-05,  5.0335355e-05,  2.9546945e-04,\n",
      "        6.1360632e-05, -5.6811350e-05, -5.6811354e-05, -5.3304480e-05,\n",
      "       -2.7350346e-05,  1.4533631e-05,  1.4533631e-05, -3.4333454e-04,\n",
      "       -4.6592228e-05,  6.1558741e-05,  6.1558749e-05, -1.0677885e-04,\n",
      "        1.0044186e-04, -2.2423896e-05, -2.2423899e-05,  6.4172375e-04,\n",
      "        5.2424548e-05, -9.6170006e-05, -9.6169992e-05, -3.8934898e-04,\n",
      "       -9.6528624e-05,  1.3353278e-04,  1.3353277e-04,  9.7017139e-05,\n",
      "       -6.0167840e-05,  5.9802907e-05,  5.9802907e-05, -2.4203377e-04,\n",
      "        1.3814204e-04, -3.6887934e-05, -3.6887948e-05,  6.4006692e-04,\n",
      "        1.0208640e-04, -2.3116154e-05, -2.3116152e-05,  5.8618747e-04,\n",
      "        7.0873011e-06,  5.0335355e-05,  5.0335355e-05,  2.9546945e-04,\n",
      "        6.1360632e-05, -5.6811350e-05, -5.6811354e-05, -5.3304480e-05,\n",
      "       -2.7350346e-05,  1.4533631e-05,  1.4533631e-05, -3.4333454e-04],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "elems = tf.random.normal((10,2))\n",
    "#NeuralN(elems)\n",
    "fn = lambda x: get_hessian(NeuralN, x)\n",
    "result = tf.vectorized_map(fn, elems)\n",
    "r = tf.reshape(result[2], [-1])\n",
    "print(result[2][:,0,0])\n",
    "t = []\n",
    "t.append(r)\n",
    "t.append(r)\n",
    "print([tf.concat(t, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5129b90",
   "metadata": {},
   "source": [
    "Why do we get a 2D vector when we insert a 2D vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11139e62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_gradient() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c835cf740454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#print(out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mδ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mδ2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mϑ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_gradient() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "NeuralN = PINN()\n",
    "\n",
    "x = tf.random.normal((1,2))\n",
    "\n",
    "out = NeuralN(x)\n",
    "#print(out)\n",
    "\n",
    "δ1 = get_gradient(NeuralN)\n",
    "δ2,ϑ = get_hessian(NeuralN)\n",
    "\n",
    "print(δ1- δ2)\n",
    "print(δ1)\n",
    "print(tf.reshape(ϑ, [-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ba692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'pinn_1/dense_4/kernel:0' shape=(2, 20) dtype=float32, numpy=\n",
       "array([[-0.01888845,  0.0703892 , -0.01261016,  0.04773998, -0.07015744,\n",
       "        -0.46251574, -0.14635238,  0.14236975, -0.21393146, -0.0766504 ,\n",
       "         0.66124874,  0.5239244 ,  0.03339515, -0.16820669, -0.04440553,\n",
       "         0.3121367 , -0.1238618 , -0.19400206, -0.27131242, -0.22926596],\n",
       "       [-0.45751068,  0.19245552,  0.16781028,  0.09677361, -0.2495658 ,\n",
       "         0.4392434 ,  0.38390887, -0.35162118,  0.09897879,  0.20463617,\n",
       "         0.08444043,  0.34904626, -0.20674534, -0.05237973,  0.17459679,\n",
       "         0.16548559, -0.36254352, -0.42186043,  0.43884766, -0.21357462]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralN.hidden[0].weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e510d2f",
   "metadata": {},
   "source": [
    "-> We need to choose appropriate dtypes so that no operation overflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c00e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fvals1(N, x):\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(x)\n",
    "        y = N(x)\n",
    "\n",
    "    dy_dx = g.gradient(y, x)\n",
    "    dy_dx = np.transpose(dy_dx.numpy())\n",
    "\n",
    "    return y, dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b017a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "5.620883e-10\n",
      "5.620883e-10\n",
      "0.0\n",
      "2.910383e-11\n",
      "2.910383e-11\n",
      "0.0\n",
      "4.656613e-10\n",
      "4.656613e-10\n",
      "0.0\n",
      "2.6031258e-10\n",
      "2.6031258e-10\n",
      "0.0\n",
      "5.820766e-11\n",
      "5.820766e-11\n",
      "0.0\n",
      "3.540634e-10\n",
      "3.540634e-10\n",
      "0.0\n",
      "1.8635544e-10\n",
      "1.8635544e-10\n",
      "0.0\n",
      "4.665699e-10\n",
      "4.665699e-10\n",
      "0.0\n",
      "1.8635544e-10\n",
      "1.8635544e-10\n",
      "0.0\n",
      "1.6463612e-10\n",
      "1.6463612e-10\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = tf.random.normal((1,2))\n",
    "    NeuralN = PINN()\n",
    "    out = NeuralN(x)\n",
    "    δ1 = get_gradient(NeuralN)\n",
    "    δ2,ϑ = get_hessian(NeuralN)\n",
    "    δ_ad = _fvals1(NeuralN, x)[1]\n",
    "    print(np.linalg.norm(δ1-δ2))\n",
    "    print(np.linalg.norm(δ1-δ_ad))\n",
    "    print(np.linalg.norm(δ2-δ_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e968d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fvals2(N, x):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as h:\n",
    "        h.watch(x)\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            y = N(x)\n",
    "\n",
    "        dy_dx = g.gradient(y, x)\n",
    "    \n",
    "    d2y_d2x = h.jacobian(dy_dx, x)\n",
    "\n",
    "    return y, dy_dx, d2y_d2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109ef374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00023168208\n",
      "0.00021419277\n",
      "0.00013859835\n",
      "0.0003060957\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x0000021FC051D700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.5743322e-05\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x0000021FC0388AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.0005692281\n",
      "2.4410165e-05\n",
      "0.0008893156\n",
      "0.00012566645\n",
      "0.00074173196\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = tf.random.normal((1,2))\n",
    "    NeuralN = PINN()\n",
    "    out = NeuralN(x)\n",
    "    δ,ϑ = get_hessian(NeuralN)\n",
    "    ϑ_ad = _fvals2(NeuralN, x)[2]\n",
    "    print(np.linalg.norm(ϑ-ϑ_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53054d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.59380233]\n",
      " [0.59357953]\n",
      " [0.593705  ]\n",
      " [0.5941088 ]\n",
      " [0.5947718 ]\n",
      " [0.5949982 ]\n",
      " [0.59471434]\n",
      " [0.5954039 ]\n",
      " [0.5949071 ]\n",
      " [0.5955576 ]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((10,))\n",
    "t = tf.random.normal((10,))\n",
    "tx = tf.stack([t, x], axis=1)\n",
    "print(NeuralN(tx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffbf82",
   "metadata": {},
   "source": [
    "Maybe gradient tape thinks that the neural network is not differentiable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f4fec",
   "metadata": {},
   "source": [
    "# Explicit derivatives of ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3e683",
   "metadata": {},
   "source": [
    "Here we only approximate the \"half\" gradient so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a110916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_ResNet(tf.keras.Model):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ResNetLayers=2,\n",
    "                 ResNetNeurons=16,\n",
    "                 ResNetStepsize=1.0,\n",
    "                 ResNetActivation='sigmoid',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(PINN_ResNet, self).__init__(**kwargs)\n",
    "        \n",
    "        #RNact = tf.keras.activations.get(ResNetActivation)\n",
    "        #RNact = my_act\n",
    "        RNact = ResNetActivation\n",
    "        \n",
    "\n",
    "        \n",
    "        self.ResNetLayers = ResNetLayers\n",
    "        self.ResNetStepsize = ResNetStepsize\n",
    "\n",
    "        self.ResNet = [tf.keras.layers.Dense(ResNetNeurons,\n",
    "                                        activation = RNact) for _ in range(self.ResNetLayers)]\n",
    "        self.wb = tf.keras.layers.Dense(1)\n",
    "        self.A = tf.keras.layers.Dense(2, use_bias=False)\n",
    "        self.c = tf.keras.layers.Dense(1, use_bias=False)\n",
    "        \n",
    "        #self.num_hidden_layers = num_hidden_layers\n",
    "        self.input_dim = 2\n",
    "        self.output_dim = 1\n",
    "\n",
    "\n",
    "        # Define NN architecture\n",
    "        \n",
    "        # Output layer\n",
    "        #self.out = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        \"\"\"Forward-pass through neural network.\"\"\"\n",
    "        \n",
    "        self.tmp_layer_output = [input_tensor]\n",
    "        \n",
    "        N = self.ResNet[0](input_tensor, training=training)\n",
    "        \n",
    "        for i in range(1, self.ResNetLayers):\n",
    "            self.tmp_layer_output.append(N)\n",
    "            N = N + self.ResNetStepsize * self.ResNet[i](N, training=training)\n",
    "        \n",
    "        Phi = self.wb(N, training=training)\n",
    "\n",
    "#         As = self.A(input_tensor, training=training)\n",
    "#         sAs = tf.keras.layers.Dot(axes=(1))([input_tensor, As])\n",
    "#         Phi += .5 * sAs\n",
    "#         Phi += self.c(input_tensor, training=training)\n",
    "            \n",
    "        return Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e957d02",
   "metadata": {},
   "source": [
    "Gradient of model, which approximates solution of pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b6137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_ResNet(R):\n",
    "    δ = get_gradient_layer(R.ResNet[-1].weights[0], R.ResNet[-1].weights[1], R.tmp_layer_output[-1], R.wb.weights[0])\n",
    "\n",
    "    δ = R.wb.weights[0] + R.ResNetStepsize * δ\n",
    " \n",
    "    for k in range(R.ResNetLayers-2, 0, -1):\n",
    "        δ = δ + R.ResNetStepsize * get_gradient_layer(R.ResNet[k].weights[0], R.ResNet[k].weights[1], R.tmp_layer_output[k], δ)\n",
    "          \n",
    "    \n",
    "    δ = get_gradient_layer(R.ResNet[0].weights[0], R.ResNet[0].weights[1], R.tmp_layer_output[0], δ)\n",
    "    \n",
    "    #return δ + np.transpose(R.A(R.tmp_layer_output[0]).numpy()) + R.c.get_weights()[0]\n",
    "    return δ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd12371",
   "metadata": {},
   "source": [
    "Something is wrong with the 'whole' gradient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e05e73c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.02221752]\n",
      " [-0.00531843]], shape=(2, 1), dtype=float32)\n",
      "[[ 0.0222175 ]\n",
      " [-0.00531846]]\n",
      "3.3967748e-08\n"
     ]
    }
   ],
   "source": [
    "Resnet = PINN_ResNet()\n",
    "\n",
    "x = tf.constant([[1., 10.]])\n",
    "\n",
    "out = Resnet(x)\n",
    "\n",
    "δ = get_gradient_ResNet(Resnet)\n",
    "\n",
    "print(δ)\n",
    "\n",
    "δ_ad = _fvals1(Resnet, x)\n",
    "\n",
    "print(δ_ad[1])\n",
    "\n",
    "print(np.linalg.norm(δ - δ_ad[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e35744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0061302e-08\n",
      "0.0\n",
      "7.450581e-09\n",
      "1.4901161e-08\n",
      "1.8626451e-08\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = tf.random.normal((1,2))\n",
    "    Resnet = PINN_ResNet()\n",
    "    out = Resnet(x)\n",
    "    δ1 = get_gradient_ResNet(Resnet)\n",
    "    δ_ad = _fvals1(Resnet, x)[1]\n",
    "    print(np.linalg.norm(δ1-δ_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d14a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_hessian_layer_ResNet(W,b,a,δ):\n",
    "    z1 = np.transpose(a @ W)  \n",
    "    b = np.reshape(b, np.shape(z1))\n",
    "    z2 = z1 + b\n",
    "    z3 = np.diag(tf.reshape(mdσ(z2), [-1])) @ δ\n",
    "    \n",
    "    z4 = md2σ(z2) * δ\n",
    "    ϑ = np.diag(tf.reshape(z4, [-1]))\n",
    "    \n",
    "    return W @ z3, W @ ϑ @ np.transpose(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600c9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hessian_ResNet(R):\n",
    "    δ,ϑ = get_gradient_hessian_layer_ResNet(R.ResNet[-1].weights[0], R.ResNet[-1].weights[1], R.tmp_layer_output[-1], R.wb.weights[0])\n",
    "\n",
    "    δ = R.wb.weights[0] + R.ResNetStepsize * δ\n",
    " \n",
    "    for k in range(R.ResNetLayers-2, 0, -1):\n",
    "        δ_new, ϑ_new_1 = get_gradient_hessian_layer_ResNet(R.ResNet[k].weights[0], R.ResNet[k].weights[1], R.tmp_layer_output[k], δ)\n",
    "        z1 = np.transpose(R.tmp_layer_output[k] @ R.ResNet[k].weights[0])  \n",
    "        b = np.reshape(R.ResNet[k].weights()[1], np.shape(z1))\n",
    "        z2 = z1 + b\n",
    "        t1 = ϑ + R.ResNetStepsize * R.ResNet[k].weights[0] @ np.diag(tf.reshape(mdσ(z2), [-1])) @ ϑ\n",
    "        ϑ_new_2 = np.transpose(t1) + R.ResNetStepsize * R.ResNet[k].weights[0] @ np.diag(tf.reshape(mdσ(z2), [-1])) @ np.transpose(t1)\n",
    "        ϑ = ϑ_new_1 + ϑ_new_2\n",
    "        δ = δ + R.ResNetStepsize * δ_new\n",
    "    \n",
    "      \n",
    "    δ, ϑ = get_gradient_hessian_hidden_layer(R.ResNet[0].weights[0], R.ResNet[0].weights[1], R.tmp_layer_output[0], δ, ϑ)\n",
    "    \n",
    "    #return δ + np.transpose(R.A(R.tmp_layer_output[0]).numpy()) + R.c.get_weights()[0], ϑ + np.transpose(R.A.get_weights()[0])\n",
    "    return δ, ϑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51c88154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02004727\n",
      "0.040664587\n",
      "0.0139674535\n",
      "0.007035735\n",
      "0.002148037\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = tf.random.normal((1,2))\n",
    "    Resnet = PINN_ResNet()\n",
    "    out = Resnet(x)\n",
    "    δ,ϑ = get_hessian_ResNet(Resnet)\n",
    "    ϑ_ad = _fvals2(Resnet, x)[2]\n",
    "    print(np.linalg.norm(ϑ-ϑ_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4dc1cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'pinn__res_net_10/dense_134/kernel:0' shape=(2, 16) dtype=float32, numpy=\n",
       "array([[-0.10830575,  0.3440271 , -0.47204584,  0.10250157,  0.2765507 ,\n",
       "         0.3026178 , -0.4115299 ,  0.47118652, -0.2142457 , -0.4787906 ,\n",
       "        -0.11594582, -0.12754828, -0.12051362, -0.05279261,  0.36103922,\n",
       "         0.36242455],\n",
       "       [ 0.53960454,  0.08977658,  0.30206776, -0.01997924, -0.40110546,\n",
       "         0.10174572, -0.47245246,  0.49537158, -0.09396005, -0.10590637,\n",
       "         0.27241457, -0.05103976, -0.2864606 , -0.0780122 , -0.2055957 ,\n",
       "        -0.30557978]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resnet.ResNet[0].weights[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
