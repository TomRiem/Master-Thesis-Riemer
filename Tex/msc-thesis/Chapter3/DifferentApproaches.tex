\chapter{Different Approaches for Solving the Drift-Diffusion Equation on Metric Graphs using PINNs}

In this chapter we present different approaches of using a physics informed neural network to solve a set of drift-diffusion equations defined in a given metric graph to given initial and boundary conditions. These approaches will differ in their approach of learning of the used neural networks. In \cref{ch3:sec1}, we discuss a approach in which the drift-diffusion equations on all edges are considered simultaneously in the learning phase. That is, we combine the drift-diffusion equations on all edges of the graph and the associated initial and boundary conditions through a cleverly defined cost function and focus only on solving this single resulting cost function in the learning phase. In \cref{ch3:sec2}, we discuss an approach similar to the idea in \cite{JagtapKharazmiKarniadakis:2020}, where we define a cost function for each edge of the graph, optimize them one by one, store certain relevant data for the interconnection for each edge, and repeat this process several times. Thus, we have as many cost functions as edges of the graph, but in the learning phase they are minimized several times in succession. Nevertheless, in both approaches the same residual network is used for each edge, the approaches only differ in the cost function of the learning method, in which the corresponding neural network and the initial and boundary conditions enter in different ways, and the course of the learning phase, simultaneously or periodically. Furthermore, we use different types and topologies of neural networks for these two approaches. We perform numerical experiments for each combination of PINN approach and neural network and compare the solutions with those generated by the FEM presented in \cref{ch2}. We are particularly interested in the accuracy and efficiency of the different approaches so that we can determine a superior method for solving the differential equation. Finally, in \cref{ch3:sec3}, we compare the performance of a PINN with explicitly calculated derivatives used inside the Hamiltonian, and thus in the corresponding residual network and cost function, with that of a PINN that uses automatic differentiation for this purpose, in order to demonstrate the capabilities of \lstinline!TensorFlow!. \\
For all experiments, we consider the graph given by the following adjacency matrix: \\

The numerical experiments are implemented in the toolbox \lstinline!Manopt.jl!. They were run on a Lenovo ThinkPad L490, 64 bit Windows system, 1.8 Ghz Intel Core i7-8565U, 32 GB RAM, with Julia 1.5.2.

\input{Chapter3/OneNN.tex}
\input{Chapter3/EdgeNN.tex}
\input{Chapter3/ADvsExplicit.tex}