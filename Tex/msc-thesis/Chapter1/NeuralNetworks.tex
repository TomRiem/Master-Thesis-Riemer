\section{Neural Networks as Function Approximators}
\label{ch1:sec3}

In this section we introduce artificial neural networks, usually just called neural networks, which are computing systems inspired by the biological neural networks that constitute animal brains. They can be used to model complex relationships between inputs and outputs or to find patterns in data. It has been shown that these systems can be used very well as classifiers as well as regressors or function approximators. \\
Artificial neural networks are based on simplified models of biological neurons, which are special cells within the nervous system which transmit information to other nerve cells. Each of these artificial neurons receives an input value, e.g. a real-valued vector, modifies it with weights and forms a biased sum. Subsequently, an activation function controls the amplitude of the output. These artificial neurons, or just neurons, are connected to each other. A single neuron may be connected to many other neurons and the total number of neurons and connections in a network may be extensive. The connections of the biological neuron are modelled as weights. Each weight determines one neuron's influence on another, a positive weight reflects an excitatory connection, while a negative weight means an inhibitory connection. The other neurons connected to this neuron take the output of this neuron as part of their input and modify it with the weight of the corresponding connection. Then the whole process is repeated. \\
However, artificial neural networks are more about an abstraction of that information processing, less about replicating biological neural networks and neurons. In 1958, the psychologist Frank Rosenblatt invented the first mathematical model for a single neuron, termed perceptron, in \cite{Rosenblatt:1958}, which was also the first artificial neural network. We want to use artificial neurons based on the perceptron and the neural networks constructed from them to approximate the function values of the solution of the differential equation.  \\
Let us We describe how a single artificial neuron transforms a reel-valued input into a one-dimensional output, as illustrated in \cref{fig4}. Let there be $n$ input values $x_1, \ldots, x_n \in \mathbb{R}$, which can be understood as the entries of a vector $x \in \mathbb{R}^n$. First one forms a biased linear combination with the input values, i.e. 
\begin{equation*}
    a = \sum^{n}_{i=1} w_i x_i + b = w^{\mathrm{T}} x + b,
\end{equation*}
where $w_1, \ldots, w_n \in \mathbb{R}$ are called weights and $b \in \mathbb{R}$ is called bias. In general, these weights and the bias are learned through data, which will be provided by the user. The weighted sum $a$ is called activation in the context of neural networks. On that weighted sum $a$ is an activation function $\sigma \colon \mathbb{R} \to \mathbb{R}$ applied, so that the output of that neuron becomes
\begin{equation*}
    y = \sigma(\sum^{n}_{i=1} w_i x_i + b) = \sigma(w^{\mathrm{T}} x + b) = \sigma(a).
\end{equation*}

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.3]{img/diagram-20220205_1.png}
    \end{center}
    \caption{Illustration of the mathematical model for a single neuron.}
    \label{fig4}
\end{figure}

The choice of activation function is determined by the nature of the input and the assumed distribution of the output. When the activation function is for example equal to the Heaviside step function, as described in \cite{Rosenblatt:1958}, i.e.
\begin{equation*}
    \sigma(x) = \begin{cases} 1 & \text{if } x \geq 0, \\ 0 & \text{if } x < 0, \end{cases}
\end{equation*}
then the artificial neuron coincides with a so-called linear support vector classifier, which is a mathematical method of pattern recognition that divides a set of objects into classes in such a way that the widest possible area around the class boundaries remains free of objects, see \cite[Chapter~7]{Bishop:2006}. \\
The activation function can be any non-constant, non-linear function, but those generally used are monotone increasing, continuous, and at least piecewise smooth. At present, the most popular activation function is the rectified linear unit, abbreviated ReLu, \cref{ReLu}. In recent decades, smoother activation functions have been used, such as the sigmoid function, \cref{Sigmoid}, or the hyperbolic tangent function, \cref{TanH}, \cite[p.~3]{LeCunBengioHinton:2015}.
\begin{align}
    \sigma(y) &=\max \{y, 0\} & & \text{ rectified linear unit (ReLU) } \label{ReLu} \\
    \sigma(y) &=\frac{1}{1+\exp (-y)} & & \text{ sigmoid } \label{Sigmoid} \\
    \sigma(y) &=\tanh (y)=\frac{\exp (y)-\exp (-y)}{\exp (y)+\exp (-y)} & & \text{ hyperbolic tangent } \label{TanH}
\end{align}
Unfortunately, a single neuron is incapable of both producing a multi-dimensional output and approximating any reasonably complicated function. This led to the creation of networks of artificial neurons, known as (artificial) neural networks. Here the neurons are typically organized into multiple layers, where the input is given to several neurons simultaneously and these then compute a multidimensional output. The neurons of one layer are connected only to neurons of the immediately preceding and immediately following layers. The outputs of the neurons of one layer is utilized as inputs to the neurons of the subsequent layer. \\
We assume that we have $L \in \mathbb{N}$ layers of artificial neurons. We use $n_l$ to denote the number of neurons in layer $1 \leq l \geq L$. As input, each of the $n_l$ neurons in layer $l$ receives the output $x^{l-1} \in \mathbb{R}^{n_{l-1}}$ of the $n_{l-1}$ neurons in the previous layer $l-1$. Each neuron in layer $l$ has its own vector of weights $w_i \in \mathbb{R}^{n_{l-1}}$, $i = 1, \ldots, n_l$. The weights of all $n_l$ neurons in layer $l$ can be conveniently organized into a matrix $W \in \mathbb{R}^{n_l \times n_{l-1}}$, where the $i$-th row is the transposed weight vector $w^{\mathrm{T}}_i$ of the $i$-th neuron. We group the $n_l$ biases of the $n_l$ neurons into a vector $b \in \mathbb{R}^{n_l}$. We obtain the nl linear combinations, which is the weighted and biased input, of the nl neurons in the l-th layer via 
\begin{equation}
    \label{propagation function}
    a^l = W^l x^{l-1} + b^l \in \mathbb{R}^{n_l},
\end{equation}
which we will call propagation function of layer $l$. \\
The same activation function will be used in all neurons of layer l, which is why we define the activation function $\sigma \colon \mathbb{R} \to \mathbb{R}$ for vector-valued input values $a \in \mathbb{R}^m$ by applying it component-wise:
\begin{equation*}
    \sigma_l \colon \mathbb{R}^{n_l} \ni a^l \mapsto \sigma_l (a^l):= \left(
        \begin{array}
            {c} \sigma_l \left( a^l_{1} \right) \\
            \vdots \\
            \sigma_l \left( a^l_{n_l} \right)
        \end{array}
        \right) \in \mathbb{R}^{n_l}.
\end{equation*}
We draw attention to the fact that the activation function $\sigma_l$ can vary from layer to layer by using the index $l$. The transformation of the input $x^{l-1} \in \mathbb{R}^{n_{l-1}}$ in the $l$-th layer can then be written as
\begin{equation}
    \label{action layer}
    \mathbb{R}^{n^{l-1}} \ni \underbrace{x^{l-1}}_{\text{input of layer } l} \mapsto x^{l}:=\underbrace{\sigma_{l}\left( W^{l} x^{l-1} + b^{l} \right)}_{\text {output of layer } l}=: F_{l} \left(x^{l-1}, W^{l}, b^{l} \right) \in \mathbb{R}^{n^{l}}, 
\end{equation}
where we express the entire process with the map $F_l \colon \mathbb{R}^{n^{l-1}} \times \mathbb{R}^{n_l \times n_{l-1}} \times \mathbb{R}^{n_l} \to \mathbb{R}^{n_l}$. \\

In artificial neural networks, topology refers to the structure of the network. This generally means how many artificial neurons are located on how many layers and how they are connected to each other. Artificial neurons can be connected in many ways to form an artificial neural network. 

In many models, neurons are arranged in layers one behind the other; 





In particular, we shall restrict our attention to the specific class of neural networks that have proven to be of greatest practical value, namely the multilayer
perceptron

Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned.

A so-called feed-forward neural network, abbreviated by FNN, consists of the composition of several of these layer-wise actions. The term feed-forward means that the information only flows in one direction, i.e. there are only connections from the neurons of one layer to the neurons of the next layer and no skipping or backward connections. It is also known as a multilayer perceptron, although this name can be misleading as the artificial neurons are usually not the perceptrons as introduced in 3. To simplify the notation of FNNs, we introduce a so-called input layer with $l=0$, which only receives external data and does not change the input and is the first layer of the network. The number of neurons in this layer corresponds to the dimension of the input. From now on, we will refer to the last layer of a general neural network, which produces the ultimate result, as the output layer. The number of neurons in this layer is equal to the dimension that the desired output should have. If an FNN has more than one layer, we refer to all layers between the input layer and the output layer as hidden layers. \\ 
Usually, an FNN is fully connected, which means that the output of each neuron in one layer would be passed to all neurons in the following layer. 



So far we have treated the weights and biases in a very abstract way and have not gone into how to determine them. 


Single layer and unlayered networks are also used. 

In addition, there are networks in which connections are allowed in both directions. The appropriate network structure is usually found using the method of trial and error, which can be supported by evolutionary algorithms and error feedback.





Using a graph, the neurons can be represented as vertices and their connections as edges. The inputs are sometimes also represented as nodes.


\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.2]{img/diagram-20220206.png}
    \end{center}
    \caption{Illustration of an artificial neural network with $L=3$ layers.}
    \label{fig5}
\end{figure}



\begin{equation*}
    \begin{aligned}
        y &=\sigma^{(3)}\left(\left(W^{(3)}\right)^{\top} \sigma^{(2)}\left(\left(W^{(2)}\right)^{\top} \sigma^{(1)}\left(\left(W^{(1)}\right)^{\top} x^{(0)}+b^{(1)}\right)+b^{(2)}\right)+b^{(3)}\right) \\
        &=F^{(3)}\left(F^{(2)}\left(F^{(1)}\left(x^{(0)}, W^{(1)}, b^{(1)}\right), W^{(2)}, b^{(2)}\right), W^{(3)}, b^{(3)}\right) \\
        &=: F\left(x^{(0)}, W^{(1)}, b^{(1)}, W^{(2)}, b^{(2)}, W^{(3)}, b^{(3)}\right) .
    \end{aligned}
\end{equation*}


The more complex the problem to be solved with the help of the neural network is, the more layers are needed. 

The process of evaluating (5.7) can then be interpreted as a forward
propagation of information through the network.



From a practical point of view, a network "learns" mainly by modifying the weights and biases of the neurons.













The most common form of machine learning, deep or not, is supervised learning.






We compute an objective function that measures the error (or distance) between the output scores and the desired pattern of scores. The machine then modifies its internal adjustable parameters to reduce  this error. These adjustable parameters, often called weights, are real numbers that can be seen as ‘knobs’ that define the input–output function of the machine. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights, and hundreds of millions of labelled examples with which to train the machine. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount. The weight vector is then adjusted in the opposite direction to the gradient vector. 

A deep-learning architecture is a multilayer stack of simple modules, all (or most) of which are subject to learning, and many of which compute non-linear input–output mappings. Each module in the stack transforms its input to increase both the selectivity and the invariance of the representation.

The backpropagation procedure to compute the gradient of an objective function with respect to the weights of a multilayer stack of modules is nothing more than a practical application of the chain rule for derivatives. The key insight is that the derivative (or gradient) of the objective with respect to the input of a module can be computed by working backwards from the gradient with respect to the output of that module

Many applications of deep learning use feedforward neural network architectures (Fig. 1), which learn to map a fixed-size input (for example, an image) to a fixed-size output (for example, a probability for each of several categories). To go from one layer to the next, a set of units compute a weighted sum of their inputs from the previous layer and pass the result through a non-linear function. At present, the most popular non-linear function is the rectified linear unit (ReLU), which is simply the half-wave rectifier. In past decades, neural nets used smoother non-linearities, such as , but the ReLU typically learns much faster in networks with many layers, allowing training of a deep supervised network without unsupervised pre-training28. Units that are not in the input or output layer are conventionally called hidden units. The hidden layers can be seen as distorting the input in a non-linear way so that categories become linearly separable by the last layer 


Zusammenhang zu daten
Perceptron
Activation Function
One layer
Neural Network
FNN
%ResNet
Machine Learning, Training 
Supervised Learning
Unsupervised Learning
Gradient Based optimization
Backpropagation 
NAS
Honrik 