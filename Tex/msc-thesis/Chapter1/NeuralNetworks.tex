\section{Neural Networks as Function Approximators}
\label{ch1:sec3}

Artificial intelligence refers to a branch of computer science that deals with the automation of intelligent behaviour, which can be understood as the intelligence displayed by machines. Artificial intelligence further refers to the attempt to emulate certain decision-making structures of humans by, for example, building and programming a computer in such a way that it can handle problems relatively independently. Today, artificial intelligence is a thriving field with many practical applications and active research topics. Many applications involve deriving a general rule from a set of data, which is called machine learning. Artificial intelligence has recently made great progress in the field of artificial neural networks, which are roughly inspired by the structure of the animal brain, are artificially simulated on the computer and can be used as universal function approximators. \\
In this section we describe artificial neural networks, usually just called neural networks, which are computing systems inspired by the biological neural networks that constitute animal brains. The original objective of the research field of artificial intelligence was to solve problems in the same way as the human brain would do, using a neural network approach. Today, neural networks can be used to model complex relationships between inputs and outputs or to find patterns in data. It has been shown that these systems can be used very well as classifiers as well as regressors or function approximators. \\
An artificial neural network is a collection of interconnected units called artificial neurons or just neurons that replicate biological neurons in a human brain, which are special cells in the nervous system that transmit information to other neurons through synapses. Each connection, like the synapses in a human brain, can transmit information, which can be understood as a signal, from one artificial neuron to another. The receiving neuron can process the signal, or even the signals, and then transmit signals to the downstream neurons that are connected to it. In common neural network types, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is calculated by a non-linear function of the sum of its inputs. Artificial neurons and their connections usually have a weight that changes during a learning process. The weight increases or decreases the strength of the signal at a connection, where a positive weight represents an excitatory connection, while a negative weight represents an inhibitory connection. \\
However, artificial neural networks are more about an abstraction of that information processing, less about replicating biological neurons or human brains. In 1958, the psychologist Frank Rosenblatt invented the first mathematical model for a single neuron, termed perceptron, in \cite{Rosenblatt:1958}, which was also the first artificial neural network. We want to use artificial neurons based on the perceptron and the neural networks constructed from them to approximate the function values of the solution of the differential equation.  \\
Let us describe how a single artificial neuron transforms a reel-valued input into a 1-dimensional output, as illustrated in \cref{fig4}. Let there be $n$ real-valued input values summarized in a vector $(x_1, \ldots, x_n)^{\mathrm{T}} = x \in \mathbb{R}^n$. First one forms a biased and weighted sum with the input values $x_1, \ldots, x_n$, which is nothing other than a linear combination, i.e. 
\begin{equation*}
    a = \sum^{n}_{i=1} w_i x_i + b = w^{\mathrm{T}} x + b,
\end{equation*}
where $(w_1, \ldots, w_n)^{\mathrm{T}} = w \in \mathbb{R}^n$ are called weights and $b \in \mathbb{R}$ is called bias. These weights and the bias are either predetermined or learned by the neuron itself through data (machine learning), but more on that later. The linear combination $a$ is called activation in the context of neural networks and a so-called activation function activation function $\sigma \colon \mathbb{R} \to \mathbb{R}$ is applied to it, so that the output of that neuron becomes
\begin{equation*}
    y = \sigma \left( \sum^{n}_{i=1} w_i x_i + b \right) = \sigma \left( w^{\mathrm{T}} x + b \right) = \sigma(a).
\end{equation*}

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.3]{img/diagram-20220205_1.png}
    \end{center}
    \caption{Illustration of the mathematical model of a single neuron.}
    \label{fig4}
\end{figure}

The choice of activation function is determined by the nature of the input and the assumed distribution of the output. When the activation function is for example equal to the Heaviside step function, as described in \cite{Rosenblatt:1958}, i.e.
\begin{equation*}
    \sigma(x) = \begin{cases} 1 & \text{if } x \geq 0, \\ 0 & \text{if } x < 0, \end{cases}
\end{equation*}
then the artificial neuron coincides with a so-called linear support vector classifier, which is a mathematical method of pattern recognition that divides a set of objects into classes in such a way that the widest possible area around the class boundaries remains free of objects, see \cite[Chapter~7]{Bishop:2006}. \\
The task of the activation function is only to turn the linear combination of the input $a$ into a non-linear output $\sigma(a)$. Therefore, any non-linear, non-constant function can be an activation function, but those generally used are additionally monotone increasing, continuous, and at least piecewise smooth. At present, the most popular activation function is the rectified linear unit, abbreviated ReLU, \cref{ReLU}. In recent decades, smoother activation functions have been used, such as the sigmoid function, \cref{Sigmoid}, or the hyperbolic tangent function, \cref{TanH}, \cite[p.~3]{LeCunBengioHinton:2015}.
\begin{align}
    \sigma(y) &=\max \{y, 0\} & & \text{ rectified linear unit (ReLU) } \label{ReLU} \\
    \sigma(y) &=\frac{1}{1+\exp (-y)} & & \text{ sigmoid } \label{Sigmoid} \\
    \sigma(y) &=\tanh (y)=\frac{\exp (y)-\exp (-y)}{\exp (y)+\exp (-y)} & & \text{ hyperbolic tangent } \label{TanH}
\end{align}

Unfortunately, a single neuron is incapable of both producing a multi-dimensional output and approximating any reasonably complicated function. This led to the creation of networks of artificial neurons, known as (artificial) neural networks. There are many different types of neural networks, which differ in their so-called architecture, which specifies how the neurons are organised, what activation functions are used and what other mathematical operations occur. Often a certain type of neural network is particularly suitable for a certain problem. A combination of different networks for problem solving is also possible. \\
In the following, we focus on the best known and one of the most important types of neural networks, which form a specific class of neural networks that have proven most effective in practice, namely (deep) feed-forward neural networks, abbreviated FNNs. In these neuronal networks, the neurons are organized in multiple layers and neurons of one layer connect only to neurons of the immediately following layer. This means that the outputs of the neurons of one layer is utilized as inputs to the neurons of the following layer. This also describes the term feed-forward, which means that the information only flows in one direction, forwards. There are no backward connections in which outputs of one layer are fed back into itself. When FNNs are extended to include backward connections, they are called recurrent neural networks. Between the neurons of two layers, multiple connection patterns are possible. FNNs are in general fully connected, which means that the output of each neuron in one layer would be passed to all neurons in the following layer. FNNs are also known as multilayer perceptrons, although this name can be misleading as the artificial neurons are usually not the perceptrons as introduced in \cite{Rosenblatt:1958}. \\
We now describe how FNNs can be modelled in mathematical terms. We assume that we have $L \in \mathbb{N}$ layers of artificial neurons. We use $n_l \in \mathbb{N}$ to denote the number of neurons in layer $1 \leq l \leq L$. These numbers describe the topology of an FNN, the number of layers is called depth and the maximum number of neurons in a layer is called width of an FNN. This is why we also speak of deep feed-forward networks, as they can often have multiple layers. \\
To simplify the notation of FNNs, we introduce a so-called input layer with $l=0$, which only receives the external data $x$. It is the first layer of the network and does not change the input $x$ in any way. The number of neurons in this layer corresponds to the dimension of the input, i.e. $x \in \mathbb{R}^{n_{0}}$. From now on, we will refer to the last layer $l = L$ of a FNN, which produces the ultimate result, as the output layer. The number of neurons in this layer is equal to the dimension that the desired output should have, i.e. $y \in \mathbb{R}^{n_{L}}$. If an FNN has more than one layer, i.e. $L>1$, we refer to all layers between the input layer and the output layer as hidden layers. If the FNN does not have one hidden layer, it is called a single layer network because only the output layer $L=1$ processes the information. \\
We consider the information processing of a single layer $1 \leq l \leq L$. As input, each of the $n_l$ neurons in layer $l$ receives the output $x^{l-1} \in \mathbb{R}^{n_{l-1}}$ of the $n_{l-1}$ neurons in the previous layer $l-1$. Each neuron in layer $l$ has its own weight vector $w_i \in \mathbb{R}^{n_{l-1}}$, $i = 1, \ldots, n_l$. The weights of all $n_l$ neurons in layer $l$ can be conveniently organized into a matrix $W \in \mathbb{R}^{n_l \times n_{l-1}}$, where the $i$-th row is the transposed weight vector, $w^{\mathrm{T}}_i$, of the $i$-th neuron. We summarize the $n_l$ biases of the $n_l$ neurons into a vector $b \in \mathbb{R}^{n_l}$. The input $x^{l-1}$ is now linearly combined $n_l$ times with the weights and biases of the $n_l$ neurons of layer $l$ via 
\begin{equation}
    \label{propagation function}
    a^l = W^l x^{l-1} + b^l \in \mathbb{R}^{n_l}.
\end{equation}
We will call \cref{propagation function} propagation function of layer $l$. \\
The same activation function will be used in all neurons of layer $l$, which is why we define the activation function $\sigma \colon \mathbb{R} \to \mathbb{R}$ for vector-valued input values $a \in \mathbb{R}^{n_l}$ by applying it component-wise:
\begin{equation*}
    \sigma_l \colon \mathbb{R}^{n_l} \ni a^l \mapsto \sigma_l (a^l):= \left(
        \begin{array}
            {c} \sigma_l \left( a^l_{1} \right) \\
            \vdots \\
            \sigma_l \left( a^l_{n_l} \right)
        \end{array}
        \right) \in \mathbb{R}^{n_l}.
\end{equation*}
We note that the activation function $\sigma_l$ can vary from layer to layer, which is why we indicate the dependency with the index $l$. The complete transformation of the input $x^{l-1} \in \mathbb{R}^{n_{l-1}}$ in the $l$-th layer can then be written as
\begin{equation}
    \label{action layer}
    \mathbb{R}^{n^{l-1}} \ni \underbrace{x^{l-1}}_{\text{input of layer } l} \mapsto x^{l}:=\underbrace{\sigma_{l}\left( W^{l} x^{l-1} + b^{l} \right)}_{\text{output of layer } l}=: f^{l}_{\Theta_l} \left( x^{l-1} \right) \in \mathbb{R}^{n^{l}}, 
\end{equation}
where $\Theta_l = (W^{l}, b^{l})$. \\

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.2]{img/diagram-20220206.png}
    \end{center}
    \caption{Illustration of a feed-forward neural network with $L=3$ layers.}
    \label{fig5}
\end{figure}

A feed-forward neural network consists of a composition of several of these layer-wise actions \cref{action layer}, which are executed one after the other. Therefore, FNNs can be well represented as a directed acyclic graph (a directed graph with no directed cycles.We omit the arrows at the edges, since the flow direction of the information is in general always known.), where the neurons are represented as vertices and the connections of the neurons are represented as edges. The input layer $l=0$ is sometimes also represented as a layer of vertices. An example of an FNN is illustrated in \cref{fig5}, where the FNN has $L=3$ layers and therefore $2$ hidden layers. The mapping of the input $x = x^0 \in \mathbb{R}^{n_0}$ to the output $y = x^3 \in \mathbb{R}^{n_3}$ by the FNN is given by 
\begin{equation}
    \label{forward propagation of information}
    \begin{aligned}
        x^3 &=\sigma_{3} \left( W^{3} \sigma_{2} \left(  W^{2} \sigma_{1} \left( W^{1} x^{0}+b^{1}\right)+b^{2}\right)+b^{3}\right) \\
        & =f^{3}_{\Theta_3} \left( f^{2}_{\Theta_2} \left( f^{1}_{\Theta_3} \left(x^{0} \right) \right) \right) \\
        & = f_{\Theta} \left( x^{0}\right). \\
    \end{aligned}
\end{equation}
The process \cref{forward propagation of information} is called model prediction of the corresponding neural network and can be interpreted as a forward propagation of information through the layers of the network. In the following, we will identify the model prediction of a neural network with the subscript $\Theta$, which constitutes the summary of all weights and biases (and other network-dependent parameters) of the network under consideration, i.e. $\Theta = (W,b)$ with $W = \{ W^l \}_{l = 1, \ldots, L}$ and $b = \{ b^l \}_{l = 1, \ldots, L}$. From \cref{forward propagation of information} it is clear that the activation functions $\sigma_l$ should be non-linear. Otherwise, the output $x^L$ is a linear function of the input $x^0$ and all layers could be combined into one output layer. \\

We have seen how an FNN produces a non-linear multidimensional output from a multidimensional input. For a network to solve a problem such as approximating a function $f \colon \mathbb{R}^n \to \mathbb{R}^m$, the weights $W$ and biases $b$ need to be properly adjusted. This is what machine learning deals with, which is one of the most common techniques in artificial intelligence. Machine learning is a generic term for the artificial generation of knowledge from experience: a neural network learns from examples that are given as a data set and can generalise them after a so-called learning phase. Neural networks do not simply learn the examples, but recognise patterns and regularities in the data. Deep learning is part of a broader family of machine learning methods that uses deep neural networks, abbreviated DNNs, to build out a comprehensive internal structure so that complex non-linear relationships can be modelled. DNNs are usually FNNs with a very high depth, i.e. with numerous hidden layers that perform different types of transformations on their input. The more complex the problem to be solved with the help of the neural network is, the more layers are needed. This number of many layers means that a lot of parameters have to be modified in a FNN, that is:
\begin{equation*}
    \underbrace{n_0 \cdot n_1 + \ldots + n_{L-1} \cdot n_L}_{\text{entries of the weight matrices}} \; \; + \underbrace{n_0 + \ldots + n_L}_{\text{entries of the bias vectors}}.
\end{equation*}
The learning through data of these deep networks is called deep learning, but it also makes use of general approaches of machine learning. Machine learning approaches are traditionally divided into three major categories, depending on the type of data available to the neural network: supervised learning, unsupervised learning and Reinforcement learning We focus on the first two. \\
Suppose we want to approximate a map
\begin{equation*}
    f \colon \mathbb{R}^n \to \mathbb{R}^m
\end{equation*}
with a FNN. Of course $n_0 = n$ and $n_L = m$ holds. In an supervised learning approach, it is assumed that a so-called training data set $\{ (x_i, y_i) \}_{i = 1, \ldots, N}$ is given, consisting of ordered pairs of inputs $x_i$ and output values $y_i$. In general, the values $y_i$ are the desired output values of the function $f$ to be approximated for the input values $x_i$, i.e. $y_i = f(x_i)$. The idea of supervised learning is to confront the neural network $f_{\Theta}$, which is to approximate the function $f$, with the correct function value $y_i$ for an input value $x_i$. The goal is to train the neural network $f_{\Theta}$ to make associations after several computations with different inputs $x_i$ and outputs $y_i$, so that the network $f_{\Theta}$ approximates the function $f$ well to a certain degree. For this purpose, a cost function is defined that compares the desired output values $y_i$ with the outputs produced by the network $f_{\Theta}(x_i)$ with the corresponding inputs $x_i$. This is generally achieved by using the so-called mean square error, abbreviated $MSE$, which is the average squared difference between the generated values $f_{\Theta}(x_i)$ and the actual values $y_i$. One then tries, with the help of a learning algorithm, to choose the weights and biases $\Theta = (W, b) = (\{ W^l \}, \{ b^l \})_{l = 1, \ldots, L}$ such that the $MSE$ can be kept as small as possible over all pairs of data $\{ (x_i, y_i) \}_{i = 1, \ldots, N}$. This can be defined as the following optimisation problem:
\begin{equation}
    \label{supervised learning}
    \begin{gathered}
        \text{ Minimize } \underbrace{\frac{1}{N}}_{\text{normalization factor}} \sum_{i=1}^{N} \lVert \underbrace{ f_{\Theta} \left(x_{i}\right)}_{\text{model prediction }} - \underbrace{y_{i}}_{\text{actual data }} \rVert^{2}_2 \\
        \\
        \text{ where } \; \Theta = (\{ W^l \}, \{ b^l \})_{l = 1, \ldots, L}, \; \; \left(W^{l}, b^{l}\right) \in \mathbb{R}^{n_l \times n_{l-1}} \times \mathbb{R}^{n_l}, \; \; l=1, \ldots, L .
    \end{gathered}
\end{equation}
Of course, loss functions other than the MSE can be used, but the MSE has become the most common because of the differentiability it provides. \\
In an unsupervised learning approach, a training dataset is given only with input values, i.e. $\{ x_i \}_{i = 1, \ldots, N}$. In this machine learning approach, the networks try to recognise structures in the given input data. The networks therefore learn from data that has not been categorised in any way. Instead of responding to feedback, unsupervised learning methods identify commonalities in the data and respond based on the presence or absence of such commonalities in each new data set. There are several methods of unsupervised learning. Again, there is the possibility of defining a cost function $C$, which is passed an input value $x_i$ and the output generated by the network $f_{\Theta}(x_i)$. The cost function $C$ depends on the problem and all a priori assumptions for the function $f$ to be approximated. However, the cost function can also be much more complicated, as its form depends on the problem at hand. Here one can again take the approach from \cref{supervised learning} and try to minimize the mean value of the cost function evaluated at all training inputs $\{ x_i \}_{i = 1, \ldots, N}$ and the output values generated by the network $\{ f_{\Theta}(x_i) \}_{i = 1, \ldots, N}$ with respect to the weights $\{ W^l \}_{l = 1, \ldots, L}$ and biases $\{ b^l \}_{l = 1, \ldots, L}$. The unsupervised learning approach offers the advantage that for many approximation problems only input values are available. \\











Honrik


In general, deep neural networks could approximate any high-dimensional function given that sufficient training data are supplied, see \cite{ArzaniDawson:2021}




A hyperparameter is a constant parameter whose value is set before the learning process begins. The values of parameters are derived via learning. Examples of hyperparameters include learning rate, the number of hidden layers and batch size.[50] The values of some hyperparameters can be dependent on those of other hyperparameters. For example, the size of some layers can depend on the overall number of layers.

We note that the type of activation function is not learned from the data, therefore it is not in the arguments of F or F in either 3 or 4. The type of activation function, like the number of layers and the number of neurons for a layer, is a so-called hyperparameter and is determined in advance by the user. 

We would like to point out that in both optimization problems the activation functions do not appear as optimization variables. This is because hyperparameters are generally not learned. Choosing the right hyperparameters is extremely difficult, generally they are discovered by trial and error. 





We compute an objective function that measures the error (or distance) between the output scores and the desired pattern of scores. The machine then modifies its internal adjustable parameters to reduce  this error. These adjustable parameters, often called weights, are real numbers that can be seen as ‘knobs’ that define the input–output function of the machine. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights, and hundreds of millions of labelled examples with which to train the machine. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount. The weight vector is then adjusted in the opposite direction to the gradient vector. 

A deep-learning architecture is a multilayer stack of simple modules, all (or most) of which are subject to learning, and many of which compute non-linear input–output mappings. Each module in the stack transforms its input to increase both the selectivity and the invariance of the representation.

The backpropagation procedure to compute the gradient of an objective function with respect to the weights of a multilayer stack of modules is nothing more than a practical application of the chain rule for derivatives. The key insight is that the derivative (or gradient) of the objective with respect to the input of a module can be computed by working backwards from the gradient with respect to the output of that module

Many applications of deep learning use feedforward neural network architectures (Fig. 1), which learn to map a fixed-size input (for example, an image) to a fixed-size output (for example, a probability for each of several categories). To go from one layer to the next, a set of units compute a weighted sum of their inputs from the previous layer and pass the result through a non-linear function. At present, the most popular non-linear function is the rectified linear unit (ReLU), which is simply the half-wave rectifier. In past decades, neural nets used smoother non-linearities, such as , but the ReLU typically learns much faster in networks with many layers, allowing training of a deep supervised network without unsupervised pre-training28. Units that are not in the input or output layer are conventionally called hidden units. The hidden layers can be seen as distorting the input in a non-linear way so that categories become linearly separable by the last layer 



Automatic differentiation in general, and the back-propagation algorithm in particular, is currently the dominant approach for training deep models by taking their derivatives with respect to the parameters (e.g., weights and biases) of the models.


Zusammenhang zu daten


Gradient Based optimization
Automatic differentiation
Backpropagation 
NAS
Honrik 